#!/usr/bin/env python3
"""
Quick OpenAI API Test - Verificaci√≥n r√°pida de conectividad
"""

import os
import sys
from pathlib import Path

def quick_openai_test():
    """Test r√°pido de conectividad con OpenAI"""
    print("üöÄ QUICK OPENAI API TEST")
    print("=" * 30)
    
    # Setup path
    project_root = Path(__file__).parent.parent if '__file__' in globals() else Path('.')
    sys.path.insert(0, str(project_root))
    
    # Test 1: Check API key
    print("\n1Ô∏è‚É£ Checking API Key...")
    try:
        from config.settings import settings
        api_key = settings.openai_api_key
        
        if not api_key:
            print("‚ùå NO API KEY FOUND")
            print("üí° Solution:")
            print("   1. Create .env file in project root")
            print("   2. Add: OPENAI_API_KEY=your_key_here")
            print("   3. Or set environment variable: export OPENAI_API_KEY=your_key")
            return False
        
        if not api_key.startswith('sk-'):
            print("‚ùå INVALID API KEY FORMAT")
            print(f"   Current: {api_key[:10]}...")
            print("üí° API key should start with 'sk-'")
            return False
        
        print(f"‚úÖ API Key found: {api_key[:10]}...{api_key[-4:]}")
        
    except Exception as e:
        print(f"‚ùå Error loading settings: {e}")
        return False
    
    # Test 2: Test direct OpenAI call
    print("\n2Ô∏è‚É£ Testing Direct OpenAI API...")
    try:
        import openai
        
        client = openai.OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "Say 'OpenAI API is working!'"}
            ],
            max_tokens=20
        )
        
        result = response.choices[0].message.content
        print(f"‚úÖ Direct API call successful!")
        print(f"   Response: {result}")
        
    except Exception as e:
        print(f"‚ùå Direct API call failed: {e}")
        return False
    
    # Test 3: Test LangChain integration
    print("\n3Ô∏è‚É£ Testing LangChain Integration...")
    try:
        from langchain_openai import ChatOpenAI
        
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0,
            openai_api_key=api_key
        )
        
        from langchain_core.messages import HumanMessage
        response = llm.invoke([HumanMessage(content="Say 'LangChain integration working!'")])
        
        print(f"‚úÖ LangChain integration successful!")
        print(f"   Response: {response.content}")
        
    except ImportError as e:
        print(f"‚ùå LangChain import failed: {e}")
        print("üí° Try: pip install langchain-openai")
        return False
    except Exception as e:
        print(f"‚ùå LangChain call failed: {e}")
        return False
    
    # Test 4: Test embeddings
    print("\n4Ô∏è‚É£ Testing Embeddings...")
    try:
        from langchain_openai import OpenAIEmbeddings
        
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=api_key
        )
        
        result = embeddings.embed_query("test embedding")
        print(f"‚úÖ Embeddings working!")
        print(f"   Vector dimension: {len(result)}")
        
    except Exception as e:
        print(f"‚ùå Embeddings failed: {e}")
        return False
    
    print("\nüéâ ALL TESTS PASSED!")
    print("‚úÖ OpenAI API integration is working correctly")
    return True

if __name__ == "__main__":
    success = quick_openai_test()
    
    if not success:
        print("\nüîß TROUBLESHOOTING STEPS:")
        print("1. Verify your OpenAI API key is correct")
        print("2. Check your internet connection")
        print("3. Ensure you have credits in your OpenAI account")
        print("4. Try: pip install --upgrade openai langchain-openai")
        sys.exit(1)
    else:
        print("\n‚úÖ Ready to run full RAG system!")
        sys.exit(0)