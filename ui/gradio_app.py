# -*- coding: utf-8 -*-
import gradio as gr
from gradio.themes.soft import Soft
from typing import List, Tuple
from src.services.rag_service import RAGService
from src.utils.logger import setup_logger
from config.settings import settings

logger = setup_logger()

class GradioRAGApp:
    """
    AplicaciÃ³n Gradio para el sistema RAG con funcionalidades avanzadas:
    - DetecciÃ³n inteligente de intenciÃ³n acadÃ©mica
    - ExpansiÃ³n automÃ¡tica de consultas
    - SelecciÃ³n dinÃ¡mica de modelos
    - Feedback visual completo para transparencia del sistema
    """
    
    def __init__(self):
        """
        Inicializa la aplicaciÃ³n con el servicio RAG.
        
        AquÃ­ establecemos la conexiÃ³n con el motor principal del sistema RAG,
        pero mantenemos el estado de inicializaciÃ³n separado para permitir
        una configuraciÃ³n step-by-step del sistema desde la interfaz.
        """
        self.rag_service = RAGService()
        self.initialized = False
    
    def initialize_service(self) -> str:
        """
        Inicializa el servicio RAG y proporciona feedback detallado al usuario.
        
        Este mÃ©todo es crucial porque valida que todos los componentes del sistema
        estÃ©n funcionando correctamente antes de permitir consultas. Es como hacer
        un "health check" completo del sistema.
        """
        try:
            if self.rag_service.initialize():
                self.initialized = True
                return "âœ… Sistema RAG inicializado correctamente con todas las funcionalidades avanzadas habilitadas:\n" + \
                       "ğŸ¯ DetecciÃ³n de intenciÃ³n acadÃ©mica\n" + \
                       "ğŸ” ExpansiÃ³n automÃ¡tica de consultas\n" + \
                       "ğŸ¤– SelecciÃ³n inteligente de modelos\n" + \
                       "ğŸ“š Base de documentos indexada y lista"
            else:
                return "âš ï¸ Sistema inicializado pero no se encontraron documentos para indexar"
        except Exception as e:
            logger.error(f"Error initializing service: {e}")
            return f"âŒ Error al inicializar: {str(e)}"
    
    def _format_intent_info(self, intent_info: dict) -> str:
        """
        Formatea la informaciÃ³n de detecciÃ³n de intenciÃ³n para presentaciÃ³n al usuario.
        
        Esta funciÃ³n es esencial para la transparencia del sistema. Cuando un investigador
        hace una pregunta, necesita entender cÃ³mo el sistema interpretÃ³ su consulta para
        poder evaluar la relevancia de la respuesta y, si es necesario, reformular
        su pregunta de manera mÃ¡s especÃ­fica.
        """
        if not intent_info:
            return ""
        
        intent_type = intent_info.get('detected_intent', 'unknown')
        confidence = intent_info.get('confidence', 0)
        specialized_prompt = intent_info.get('specialized_prompt_used', False)
        processing_time = intent_info.get('processing_time_ms', 0)
        
        # Mapear tipos de intenciÃ³n a nombres comprensibles para el usuario
        # Estos nombres estÃ¡n diseÃ±ados para que investigadores sin conocimiento tÃ©cnico
        # puedan entender inmediatamente quÃ© tipo de respuesta pueden esperar
        intent_names = {
            'definition': 'ğŸ“– DefiniciÃ³n Conceptual',
            'comparison': 'âš–ï¸ AnÃ¡lisis Comparativo', 
            'state_of_art': 'ğŸŒŸ Estado del Arte',
            'gap_analysis': 'ğŸ” AnÃ¡lisis de Gaps',
            'unknown': 'â“ Consulta General',
            'error': 'âš ï¸ Error de ClasificaciÃ³n'
        }
        
        intent_name = intent_names.get(intent_type, f'â“ {intent_type}')
        
        # Construir mensaje informativo con diferentes niveles de detalle
        info_parts = [f"**Tipo de consulta detectada:** {intent_name}"]
        
        if confidence > 0:
            # Los emojis ayudan a transmitir rÃ¡pidamente el nivel de confianza
            confidence_emoji = "ğŸ¯" if confidence >= 0.8 else "ğŸ²" if confidence >= 0.6 else "â“"
            info_parts.append(f"**Confianza:** {confidence_emoji} {confidence:.0%}")
        
        if specialized_prompt and intent_type not in ['unknown', 'error']:
            info_parts.append("**Respuesta optimizada:** âœ¨ Usando template acadÃ©mico especializado")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de anÃ¡lisis:** âš¡ {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
    
    def _format_expansion_info(self, expansion_info: dict) -> str:
        """
        Formatea la informaciÃ³n de expansiÃ³n de consulta para mostrar al usuario.
        
        La expansiÃ³n de consultas puede ser un concepto abstracto para muchos usuarios.
        Esta funciÃ³n hace visible ese proceso, mostrando exactamente quÃ© tÃ©rminos
        adicionales estÃ¡ usando el sistema para buscar informaciÃ³n relevante.
        Esto ayuda a los investigadores a entender por quÃ© ciertos documentos
        aparecieron en los resultados incluso si no contenÃ­an exactamente sus tÃ©rminos originales.
        """
        if not expansion_info or expansion_info.get('expansion_count', 0) == 0:
            return ""
        
        expanded_terms = expansion_info.get('expanded_terms', [])
        processing_time = expansion_info.get('processing_time_ms', 0)
        strategy_used = expansion_info.get('strategy_used', 'unknown')
        
        info_parts = [f"**TÃ©rminos expandidos:** ğŸ” {', '.join(expanded_terms[:5])}"]
        
        if len(expanded_terms) > 5:
            info_parts.append(f"*... y {len(expanded_terms) - 5} tÃ©rminos mÃ¡s*")
        
        if strategy_used != 'unknown':
            strategy_names = {
                'conservative': 'Conservadora',
                'moderate': 'Moderada', 
                'comprehensive': 'Comprehensiva'
            }
            strategy_display = strategy_names.get(strategy_used, strategy_used)
            info_parts.append(f"**Estrategia:** ğŸ“Š {strategy_display}")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de expansiÃ³n:** âš¡ {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
    
    def _format_model_info(self, model_info: dict) -> str:
        """
        Formatea la informaciÃ³n del modelo seleccionado para mostrar al usuario.
        
        La selecciÃ³n automÃ¡tica de modelos es una de las caracterÃ­sticas mÃ¡s sofisticadas
        del sistema. Esta funciÃ³n hace transparente esa decisiÃ³n, permitiendo que los
        usuarios entiendan por quÃ© el sistema eligiÃ³ un modelo particular para su consulta.
        Esto es especialmente importante en contextos acadÃ©micos donde la reproducibilidad
        y la comprensiÃ³n del proceso son fundamentales.
        """
        if not model_info:
            return ""
        
        model_name = model_info.get('selected_model', 'unknown')
        complexity_score = model_info.get('complexity_score', 0)
        reasoning = model_info.get('reasoning', '')
        
        # Mapear modelos tÃ©cnicos a nombres que los usuarios puedan entender fÃ¡cilmente
        # Incluimos informaciÃ³n sobre las fortalezas de cada modelo
        model_names = {
            'gpt-4o': 'ğŸ§  GPT-4o (AnÃ¡lisis AcadÃ©mico Profundo)',
            'gpt-4o-mini': 'âš¡ GPT-4o-mini (Respuesta RÃ¡pida y Eficiente)',
            'gpt-3.5-turbo': 'ğŸ’¨ GPT-3.5-turbo (Consultas Directas)'
        }
        
        model_display = model_names.get(model_name, f'ğŸ¤– {model_name}')
        
        info_parts = [f"**Modelo seleccionado:** {model_display}"]
        
        if complexity_score > 0:
            # Visual indicators para el nivel de complejidad detectado
            complexity_emoji = "ğŸ”¥" if complexity_score >= 0.7 else "âš¡" if complexity_score >= 0.4 else "ğŸ’¨"
            info_parts.append(f"**Complejidad detectada:** {complexity_emoji} {complexity_score:.0%}")
        
        # Agregar reasoning si estÃ¡ disponible y es informativo
        if reasoning and len(reasoning) < 100:  # Solo mostrar si es conciso
            info_parts.append(f"**RazÃ³n:** {reasoning}")
        
        return "\n".join(info_parts)
    
    def chat_response(self, message: str, history: List[Tuple[str, str]]) -> Tuple[str, str]:
        """
        Procesa las consultas del usuario y genera respuestas con informaciÃ³n enriquecida.
        
        Esta es la funciÃ³n central que orquesta todo el pipeline RAG avanzado:
        1. Valida el estado del sistema
        2. Procesa la consulta a travÃ©s del pipeline completo
        3. Extrae y formatea toda la metadata del proceso
        4. Presenta tanto la respuesta como la informaciÃ³n del sistema
        
        El retorno de una tupla permite separar la respuesta principal (que es lo que
        el usuario busca) de la informaciÃ³n del sistema (que proporciona transparencia
        sobre cÃ³mo se generÃ³ esa respuesta).
        """
        if not self.initialized:
            return "âŒ El sistema no estÃ¡ inicializado. Por favor inicialÃ­zalo primero.", ""
        
        if not message.strip():
            return "Por favor, escribe una pregunta acadÃ©mica.", ""
        
        try:
            # Obtener respuesta completa con toda la metadata del pipeline
            result = self.rag_service.query(message, include_sources=True)
            
            # La respuesta principal es lo que el usuario realmente quiere leer
            main_response = result['answer']
            
            # Construir informaciÃ³n del sistema de manera modular
            # Cada secciÃ³n proporciona transparencia sobre una parte diferente del proceso
            system_info_parts = []
            
            # SecciÃ³n 1: AnÃ¡lisis de la consulta (detecciÃ³n de intenciÃ³n)
            intent_info = result.get('intent_info', {})
            if intent_info:
                intent_details = self._format_intent_info(intent_info)
                if intent_details:
                    system_info_parts.append("### ğŸ¯ AnÃ¡lisis de Consulta")
                    system_info_parts.append(intent_details)
            
            # SecciÃ³n 2: ExpansiÃ³n de consulta (tÃ©rminos adicionales utilizados)
            expansion_info = result.get('expansion_info', {})
            if expansion_info and expansion_info.get('expansion_count', 0) > 0:
                expansion_details = self._format_expansion_info(expansion_info)
                if expansion_details:
                    system_info_parts.append("### ğŸ” ExpansiÃ³n de Consulta")
                    system_info_parts.append(expansion_details)
            
            # SecciÃ³n 3: SelecciÃ³n de modelo (por quÃ© se eligiÃ³ este modelo)
            model_info = result.get('model_info', {})
            if model_info:
                model_details = self._format_model_info(model_info)
                if model_details:
                    system_info_parts.append("### ğŸ¤– SelecciÃ³n de Modelo")
                    system_info_parts.append(model_details)
            
            # SecciÃ³n 4: Fuentes consultadas (transparencia sobre los documentos utilizados)
            sources = result.get('sources', [])
            if sources:
                system_info_parts.append("### ğŸ“š Fuentes Consultadas")
                source_list = []
                for i, source in enumerate(sources[:3], 1):  # Mostrar mÃ¡ximo 3 fuentes principales
                    file_name = source.get('metadata', {}).get('file_name', 'Documento desconocido')
                    source_list.append(f"{i}. **{file_name}**")
                system_info_parts.append("\n".join(source_list))
                
                if len(sources) > 3:
                    system_info_parts.append(f"*... y {len(sources) - 3} fuentes adicionales*")
            
            # Combinar toda la informaciÃ³n del sistema en un panel cohesivo
            system_info = "\n\n".join(system_info_parts) if system_info_parts else ""
            
            return main_response, system_info
            
        except Exception as e:
            logger.error(f"Error in chat response: {e}")
            error_msg = f"âŒ Error al procesar la pregunta: {str(e)}"
            return error_msg, ""
    
    def reindex_documents(self) -> str:
        """
        Reindexar documentos cuando se agregan nuevos archivos o se quiere refrescar la base.
        
        Esta operaciÃ³n es costosa en tÃ©rminos de tiempo y recursos, por lo que incluimos
        advertencias claras y feedback detallado sobre el proceso.
        """
        try:
            count = self.rag_service.reindex_documents()
            if count > 0:
                return f"âœ… Reindexados {count} documentos correctamente"
            else:
                return "âš ï¸ No se encontraron documentos para reindexar"
        except Exception as e:
            logger.error(f"Error reindexing: {e}")
            return f"âŒ Error al reindexar: {str(e)}"

    def get_faq_markdown(self) -> str:
        """
        Genera contenido dinÃ¡mico de preguntas frecuentes basado en el uso real del sistema.
        
        Esta funciÃ³n es un ejemplo de cÃ³mo el sistema aprende de sus usuarios.
        Las preguntas mÃ¡s frecuentes se pueden usar para mejorar la documentaciÃ³n,
        identificar patrones de uso, y optimizar las respuestas del sistema.
        """
        faqs = self.rag_service.get_frequent_questions()
        if not faqs:
            return "_No hay preguntas frecuentes registradas aÃºn._"
        lines = "\n".join(f"- {q}" for q in faqs)
        return f"**Preguntas frecuentes:**\n{lines}"
    
    def create_interface(self) -> gr.Blocks:
        """
        Crea la interfaz de usuario completa con todas las funcionalidades integradas.
        
        Esta funciÃ³n construye la interfaz que expone todas las capacidades del sistema
        de manera intuitiva. El diseÃ±o estÃ¡ pensado para investigadores acadÃ©micos
        que necesitan tanto poder como facilidad de uso.
        """
        with gr.Blocks(
            theme=Soft(),
            css="""
            /* Estilos personalizados para mejorar la experiencia visual */
            .system-info {
                background-color: #f8f9fa !important;
                border: 1px solid #e9ecef !important;
                border-radius: 8px !important;
                padding: 12px !important;
                margin-top: 8px !important;
                font-size: 0.9em !important;
                color: #2c3e50 !important;
            }
            .system-info h3 {
                color: #34495e !important;
                font-weight: bold !important;
                margin-bottom: 8px !important;
            }
            .system-info p {
                color: #2c3e50 !important;
                margin-bottom: 4px !important;
            }
            .system-info strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            /* Indicadores visuales para diferentes tipos de intenciÃ³n */
            .intent-indicator {
                display: inline-block !important;
                padding: 4px 8px !important;
                border-radius: 12px !important;
                font-size: 0.8em !important;
                font-weight: bold !important;
                margin-right: 8px !important;
            }
            .definition { 
                background-color: #e3f2fd !important; 
                color: #1565c0 !important; 
            }
            .comparison { 
                background-color: #f3e5f5 !important; 
                color: #7b1fa2 !important; 
            }
            .state_of_art { 
                background-color: #e8f5e8 !important; 
                color: #2e7d32 !important; 
            }
            .gap_analysis { 
                background-color: #fff3e0 !important; 
                color: #ef6c00 !important; 
            }
            /* Asegurar legibilidad en el panel lateral */
            .gr-column .gr-markdown {
                color: #2c3e50 !important;
            }
            .gr-column .gr-markdown h3 {
                color: #34495e !important;
                font-weight: bold !important;
            }
            .gr-column .gr-markdown strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            """
        ) as interface:
            
            # Header principal con branding y descripciÃ³n del sistema
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 2rem;">
                <h1>ğŸ¤– Sistema RAG Avanzado para InvestigaciÃ³n AcadÃ©mica</h1>
                <p>Especializado en IA para Historias de Usuario - Con Inteligencia Artificial Multicapa</p>
                <p><small>
                    ğŸ¯ DetecciÃ³n automÃ¡tica de intenciÃ³n &nbsp;â€¢&nbsp; 
                    ğŸ” ExpansiÃ³n inteligente de consultas &nbsp;â€¢&nbsp; 
                    ğŸ¤– SelecciÃ³n dinÃ¡mica de modelos &nbsp;â€¢&nbsp; 
                    ğŸ“Š Transparencia completa del proceso
                </small></p>
            </div>
            """)
            
            with gr.Tabs():
                # Tab principal - Chat AcadÃ©mico Inteligente
                with gr.TabItem("ğŸ’¬ Chat AcadÃ©mico Inteligente"):
                    gr.Markdown("### Asistente de InvestigaciÃ³n con IA Multicapa")
                    gr.Markdown("""
                    Haz preguntas acadÃ©micas y observa cÃ³mo el sistema combina mÃºltiples tÃ©cnicas de IA:
                    - ğŸ¯ **Detecta automÃ¡ticamente** el tipo de consulta (definiciÃ³n, comparaciÃ³n, estado del arte, gaps)
                    - ğŸ” **Expande tu consulta** con sinÃ³nimos acadÃ©micos y tÃ©rminos relacionados relevantes  
                    - ğŸ¤– **Selecciona el modelo apropiado** (GPT-4o para anÃ¡lisis complejos, GPT-4o-mini para consultas simples)  
                    - âœ¨ **Optimiza la respuesta** usando templates acadÃ©micos especializados por tipo de intenciÃ³n
                    - ğŸ“Š **Muestra todo el proceso** para transparencia y reproducibilidad acadÃ©mica
                    """)
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            # Ãrea principal de conversaciÃ³n
                            chatbot = gr.Chatbot(
                                label="ConversaciÃ³n AcadÃ©mica Inteligente",
                                height=500,
                                type='messages',
                                show_label=True
                            )
                            
                            with gr.Row():
                                msg = gr.Textbox(
                                    label="Tu pregunta de investigaciÃ³n",
                                    placeholder="Ej: Compare las metodologÃ­as de IA para historias de usuario...",
                                    scale=4,
                                    lines=2
                                )
                                send_btn = gr.Button("Enviar", variant="primary", scale=1)
                            
                            with gr.Row():
                                clear_btn = gr.Button("ğŸ—‘ï¸ Limpiar Chat", variant="secondary")
                        
                        with gr.Column(scale=1):
                            # Panel de informaciÃ³n del sistema - la clave de la transparencia
                            system_info_display = gr.Markdown(
                                label="ğŸ“Š InformaciÃ³n del Sistema",
                                value="*EnvÃ­a una consulta para ver cÃ³mo el sistema analiza tu pregunta con IA multicapa*",
                                elem_classes=["system-info"],
                                visible=True
                            )
                    
                    # Ejemplos acadÃ©micos organizados por tipo para educar al usuario
                    with gr.Accordion("ğŸ“‹ Ejemplos por Tipo de Consulta", open=False):
                        gr.Markdown("""
                        **ğŸ”µ Definiciones Conceptuales (ActivarÃ¡ template especializado en definiciones):**
                        - "Â¿QuÃ© es Natural Language Processing en requirements engineering?"
                        - "Define machine learning aplicado a historias de usuario"
                        - "Explica el concepto de automated requirements generation"
                        
                        **ğŸŸ£ AnÃ¡lisis Comparativos (ActivarÃ¡ template de comparaciÃ³n sistemÃ¡tica):**
                        - "Compara supervised vs unsupervised learning para user stories"
                        - "Diferencias entre rule-based y ML approaches en requirements"
                        - "Ventajas y desventajas de BERT vs GPT para anÃ¡lisis de texto"
                        
                        **ğŸŸ¢ Estado del Arte (ActivarÃ¡ template de sÃ­ntesis temporal):**
                        - "Estado del arte en IA para automatizaciÃ³n de requirements"
                        - "Enfoques actuales en NLP para historias de usuario"
                        - "Tendencias recientes en AI-assisted software development"
                        
                        **ğŸŸ  AnÃ¡lisis de Gaps (ActivarÃ¡ template de identificaciÃ³n de oportunidades):**
                        - "Â¿QuÃ© limitaciones tienen los mÃ©todos actuales de NLP para user stories?"
                        - "Gaps de investigaciÃ³n en automated requirements engineering"
                        - "Â¿QuÃ© oportunidades existen para mejorar las tÃ©cnicas actuales?"
                        """)

                    # FAQ dinÃ¡micas - aprendizaje del sistema
                    faq_display = gr.Markdown(value=self.get_faq_markdown())
                    
                    def respond(message, chat_history):
                        """
                        Handler principal para las respuestas del chat.
                        
                        Esta funciÃ³n coordina todo el proceso de respuesta y actualiza
                        tanto el historial de chat como la informaciÃ³n del sistema.
                        """
                        if not message.strip():
                            return chat_history, "", self.get_faq_markdown(), ""
                        
                        # Procesar la consulta a travÃ©s del pipeline completo
                        bot_response, system_info = self.chat_response(message, chat_history)
                        
                        # Actualizar historial en formato compatible con Gradio
                        chat_history.append({"role": "user", "content": message})
                        chat_history.append({"role": "assistant", "content": bot_response})

                        return chat_history, "", self.get_faq_markdown(), system_info
                    
                    # Event handlers para interacciÃ³n del usuario
                    send_btn.click(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    msg.submit(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    clear_btn.click(
                        lambda: ([], "", self.get_faq_markdown(), "*EnvÃ­a una consulta para ver el anÃ¡lisis multicapa del sistema*"),
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                
                # Tab de administraciÃ³n del sistema
                with gr.TabItem("âš™ï¸ AdministraciÃ³n del Sistema"):
                    gr.Markdown("### GestiÃ³n del Sistema RAG Inteligente")
                    
                    with gr.Row():
                        init_btn = gr.Button("ğŸš€ Inicializar Sistema", variant="primary")
                        reindex_btn = gr.Button("ğŸ“š Reindexar Documentos", variant="secondary")
                    
                    status_output = gr.Textbox(
                        label="Estado del Sistema",
                        interactive=False,
                        lines=3
                    )
                    
                    # InformaciÃ³n detallada de configuraciÃ³n para transparency tÃ©cnica
                    gr.Markdown("### ConfiguraciÃ³n del Sistema RAG Inteligente")
                    gr.Markdown(f"""
                    **ğŸ§  DetecciÃ³n de IntenciÃ³n AcadÃ©mica:**
                    - ğŸ¯ **Estado**: `{'Habilitada' if settings.enable_intent_detection else 'Deshabilitada'}`
                    - ğŸ“Š **Umbral de confianza**: `{settings.intent_confidence_threshold}`
                    - âš¡ **Tiempo mÃ¡ximo de procesamiento**: `{settings.intent_max_processing_time_ms}ms`
                    
                    **ğŸ” ExpansiÃ³n Inteligente de Consultas:**
                    - ğŸ¯ **Estado**: `{'Habilitada' if settings.enable_query_expansion else 'Deshabilitada'}`
                    - ğŸ“Š **MÃ¡ximo tÃ©rminos expandidos**: `{settings.max_expansion_terms}`
                    - ğŸ¨ **Estrategia de expansiÃ³n**: `{settings.expansion_strategy}`
                    - âš¡ **Tiempo mÃ¡ximo de procesamiento**: `{settings.expansion_max_processing_time_ms}ms`
                    
                    **ğŸ¤– SelecciÃ³n Inteligente de Modelos:**
                    - ğŸ§  **Modelo para consultas complejas**: `{settings.complex_model}`
                    - âš¡ **Modelo para consultas simples**: `{settings.simple_model}`
                    - ğŸ¯ **Umbral de complejidad**: `{settings.complexity_threshold}`
                    - ğŸ”„ **SelecciÃ³n automÃ¡tica**: `{'Activada' if settings.enable_smart_selection else 'Desactivada'}`
                    
                    **ğŸ“š ConfiguraciÃ³n RAG Base:**
                    - ğŸ“ **Directorio de documentos**: `{settings.documents_path}`
                    - ğŸ—ƒï¸ **Base de datos vectorial**: `{settings.vector_db_path}`
                    - ğŸ”¤ **Modelo de embeddings**: `{settings.embedding_model}`
                    - ğŸ“Š **TamaÃ±o de chunk**: `{settings.chunk_size}`
                    - ğŸ”— **Overlap de chunk**: `{settings.chunk_overlap}`
                    - ğŸ“– **Documentos por consulta**: `{settings.max_documents}`
                    """)
                
                # Tab de guÃ­a acadÃ©mica - educaciÃ³n del usuario
                with gr.TabItem("ğŸ“š GuÃ­a de InvestigaciÃ³n Inteligente"):
                    gr.Markdown("""
                    ## ğŸ“ Sistema RAG Inteligente para InvestigaciÃ³n AcadÃ©mica
                    
                    ### ğŸ§  Inteligencia Artificial Multicapa
                    
                    Este sistema combina **cuatro niveles de IA** para optimizar tu experiencia de investigaciÃ³n:
                    
                    #### ğŸ¯ **Nivel 1: DetecciÃ³n AutomÃ¡tica de IntenciÃ³n**
                    El sistema analiza tu consulta en **menos de 200ms** para determinar quÃ© tipo de respuesta necesitas:
                    
                    - **ğŸ“– DefiniciÃ³n Conceptual** â†’ Estructura la respuesta con definiciÃ³n formal, contexto histÃ³rico y aplicaciones
                    - **âš–ï¸ AnÃ¡lisis Comparativo** â†’ Organiza la informaciÃ³n en anÃ¡lisis sistemÃ¡tico y tablas comparativas  
                    - **ğŸŒŸ Estado del Arte** â†’ Presenta cronologÃ­a, tendencias actuales y consenso acadÃ©mico
                    - **ğŸ” AnÃ¡lisis de Gaps** â†’ Identifica limitaciones, oportunidades y direcciones futuras
                    
                    #### ğŸ” **Nivel 2: ExpansiÃ³n Inteligente de Consulta**
                    Basado en tu intenciÃ³n detectada, expande automÃ¡ticamente tu consulta:
                    
                    - **SinÃ³nimos acadÃ©micos** â†’ "machine learning" se expande a "ML", "AI", "predictive modeling"
                    - **TÃ©rminos relacionados** â†’ "user stories" incluye "acceptance criteria", "requirements"
                    - **Variaciones contextuales** â†’ Adaptadas al tipo de consulta especÃ­fica
                    
                    #### ğŸ¤– **Nivel 3: SelecciÃ³n Inteligente de Modelo**
                    Basado en la complejidad de tu consulta expandida, elige automÃ¡ticamente:
                    
                    - **ğŸ§  GPT-4o** para anÃ¡lisis acadÃ©micos complejos, comparaciones metodolÃ³gicas y sÃ­ntesis profundas
                    - **âš¡ GPT-4o-mini** para definiciones claras, consultas directas y respuestas rÃ¡pidas
                    
                    #### âœ¨ **Nivel 4: OptimizaciÃ³n de Template**
                    Usando tu intenciÃ³n detectada, aplica templates acadÃ©micos especializados:
                    
                    - **Estructura acadÃ©mica apropiada** para cada tipo de consulta
                    - **Enfoque metodolÃ³gico especÃ­fico** (cronolÃ³gico, comparativo, analÃ­tico)
                    - **Formato optimizado** para tu contexto de investigaciÃ³n
                    
                    ### ğŸš€ CÃ³mo Aprovechar al MÃ¡ximo el Sistema
                    
                    #### **Para InvestigaciÃ³n de Tesis sobre IA y User Stories:**
                    
                    **ğŸ” ExploraciÃ³n Inicial:**
                    1. "Estado del arte en IA para historias de usuario" (activarÃ¡ anÃ¡lisis cronolÃ³gico con expansiÃ³n temporal)
                    2. "Â¿QuÃ© es automated requirements generation?" (activarÃ¡ definiciÃ³n estructurada con sinÃ³nimos tÃ©cnicos)
                    
                    **ğŸ“Š AnÃ¡lisis Comparativo:**
                    1. "Compara NLP vs Machine Learning para requirements analysis" (expandirÃ¡ con variaciones metodolÃ³gicas)
                    2. "Ventajas y desventajas de rule-based vs deep learning approaches" (incluirÃ¡ tÃ©rminos contrastivos)
                    
                    **ğŸ¯ IdentificaciÃ³n de Oportunidades:**
                    1. "Â¿QuÃ© limitaciones tienen las tÃ©cnicas actuales de NLP para user stories?" (expandirÃ¡ con tÃ©rminos de gap analysis)
                    2. "Gaps de investigaciÃ³n en automated requirements engineering" (incluirÃ¡ sinÃ³nimos de limitaciones)
                    
                    ### ğŸ’¡ Indicadores Visuales del Sistema
                    
                    Observa el **panel lateral** durante tus consultas para ver:
                    
                    - **ğŸ¯ Tipo de consulta detectada** con nivel de confianza y reasoning
- **ğŸ” TÃ©rminos expandidos** agregados automÃ¡ticamente con estrategia utilizada
                   - **ğŸ¤– Modelo seleccionado** y razÃ³n de la selecciÃ³n basada en complejidad  
                   - **âœ¨ OptimizaciÃ³n aplicada** (si usa template especializado)
                   - **ğŸ“š Fuentes consultadas** para tu respuesta especÃ­fica
                    
                   ### ğŸ“ Resultados de InvestigaciÃ³n Optimizados
                    
                   **Para Definiciones:**
                   - Estructura acadÃ©mica formal con contexto histÃ³rico
                   - Referencias a autores principales y papers fundamentales
                   - Conexiones con conceptos relacionados
                   - ExpansiÃ³n automÃ¡tica con sinÃ³nimos tÃ©cnicos y variaciones
                    
                   **Para Comparaciones:**
                   - Matrices comparativas sistemÃ¡ticas
                   - AnÃ¡lisis de ventajas/desventajas equilibrado
                   - Recomendaciones basadas en contexto de uso
                   - TÃ©rminos contrastivos agregados automÃ¡ticamente
                    
                   **Para Estado del Arte:**
                   - EvoluciÃ³n temporal de enfoques
                   - IdentificaciÃ³n de tendencias emergentes  
                   - AnÃ¡lisis de consenso vs controversias
                   - ExpansiÃ³n con indicadores temporales y de tendencia
                    
                   **Para AnÃ¡lisis de Gaps:**
                   - CategorizaciÃ³n de limitaciones por tipo
                   - Oportunidades especÃ­ficas de investigaciÃ³n
                   - ConexiÃ³n con trabajos futuros sugeridos
                   - TÃ©rminos de limitaciÃ³n y oportunidad expandidos
                    
                   ### ğŸ”¬ OptimizaciÃ³n para tu Dominio EspecÃ­fico
                   
                   El sistema estÃ¡ **pre-optimizado** para investigaciÃ³n en:
                   - âœ… Inteligencia Artificial aplicada a Software Engineering
                   - âœ… Natural Language Processing para Requirements  
                   - âœ… Machine Learning en User Story Analysis
                   - âœ… Automated Software Development Tools
                   - âœ… AI-Assisted Development Methodologies
                    
                   ### ğŸ“ˆ Consejos para Consultas de Alta Calidad
                   
                   **ğŸ¯ SÃ© especÃ­fico en tu intenciÃ³n:**
                   - âŒ "machine learning" 
                   - âœ… "Â¿QuÃ© tÃ©cnicas de machine learning se usan para analizar historias de usuario?"
                   - ğŸ” *El sistema expandirÃ¡ automÃ¡ticamente con tÃ©rminos relacionados*
                    
                   **ğŸ”— Conecta conceptos:**
                   - âŒ "NLP tools"
                   - âœ… "Compare herramientas de NLP para extracciÃ³n automÃ¡tica de requirements"
                   - ğŸ” *ActivarÃ¡ template comparativo y expandirÃ¡ con variaciones tÃ©cnicas*
                    
                   **ğŸ“Š Solicita anÃ¡lisis estructurado:**
                   - âŒ "research gaps"
                   - âœ… "Â¿QuÃ© limitaciones identifican los estudios actuales en automated user story generation?"
                   - ğŸ” *DetectarÃ¡ gap analysis y expandirÃ¡ con sinÃ³nimos de limitaciones*
                    
                   ### ğŸš€ El Futuro de tu InvestigaciÃ³n
                   
                   Con este sistema inteligente multicapa, puedes:
                   - **âš¡ Acelerar** tu revisiÃ³n de literatura 5-10x con expansiÃ³n automÃ¡tica
                   - **ğŸ¯ Identificar** gaps de investigaciÃ³n automÃ¡ticamente con detecciÃ³n de intenciÃ³n  
                   - **ğŸ“Š Comparar** metodologÃ­as de manera sistemÃ¡tica con templates especializados
                   - **ğŸ” Descubrir** conexiones entre diferentes lÃ­neas de investigaciÃ³n mediante expansiÃ³n semÃ¡ntica
                   - **ğŸ“ˆ Optimizar** la calidad acadÃ©mica con selecciÃ³n inteligente de modelos
                   - **ğŸ”¬ Reproducir** resultados con total transparencia del proceso
                   """)
           
           # Event handlers para funcionalidades administrativas
            init_btn.click(
                fn=self.initialize_service,
                outputs=status_output
            )
            
            reindex_btn.click(
                fn=self.reindex_documents,
                outputs=status_output
            )
        
        return interface

    def launch(self, **kwargs):
        """
        Lanza la aplicaciÃ³n con configuraciÃ³n optimizada para investigaciÃ³n acadÃ©mica.
        
        Esta funciÃ³n inicia el servidor web que expone toda la funcionalidad del sistema
        RAG inteligente. La configuraciÃ³n por defecto estÃ¡ optimizada para uso acadÃ©mico.
        """
        interface = self.create_interface()
        
        # ConfiguraciÃ³n por defecto optimizada
        launch_kwargs = {
            'server_port': settings.server_port,
            'share': settings.share_gradio,
            'show_error': True,
            'quiet': False,
            **kwargs
        }
        
        logger.info(f"Launching advanced RAG app with multicapa AI on port {launch_kwargs['server_port']}")
        logger.info("Features enabled: Intent Detection + Query Expansion + Smart Model Selection")
        interface.launch(**launch_kwargs)