# -*- coding: utf-8 -*-
import gradio as gr
from gradio.themes.soft import Soft
from typing import List, Tuple
from src.services.rag_service import RAGService
from src.utils.logger import setup_logger
from config.settings import settings

logger = setup_logger()

class GradioRAGApp:
    """
    Aplicaci√≥n Gradio para el sistema RAG con funcionalidades avanzadas:
    - Detecci√≥n inteligente de intenci√≥n acad√©mica
    - Expansi√≥n autom√°tica de consultas
    - Selecci√≥n din√°mica de modelos
    - Feedback visual completo para transparencia del sistema
    """
    
    def __init__(self):
        """
        Inicializa la aplicaci√≥n con el servicio RAG.
        
        Aqu√≠ establecemos la conexi√≥n con el motor principal del sistema RAG,
        pero mantenemos el estado de inicializaci√≥n separado para permitir
        una configuraci√≥n step-by-step del sistema desde la interfaz.
        """
        self.rag_service = RAGService()
        self.initialized = False
    
    def initialize_service(self) -> str:
        """
        Inicializa el servicio RAG y proporciona feedback detallado al usuario.
        
        Este m√©todo es crucial porque valida que todos los componentes del sistema
        est√©n funcionando correctamente antes de permitir consultas. Es como hacer
        un "health check" completo del sistema.
        """
        try:
            if self.rag_service.initialize():
                self.initialized = True
                return "‚úÖ Sistema RAG inicializado correctamente con todas las funcionalidades avanzadas habilitadas:\n" + \
                       "üéØ Detecci√≥n de intenci√≥n acad√©mica\n" + \
                       "üîç Expansi√≥n autom√°tica de consultas\n" + \
                       "ü§ñ Selecci√≥n inteligente de modelos\n" + \
                       "üìö Base de documentos indexada y lista"
            else:
                return "‚ö†Ô∏è Sistema inicializado pero no se encontraron documentos para indexar"
        except Exception as e:
            logger.error(f"Error initializing service: {e}")
            return f"‚ùå Error al inicializar: {str(e)}"
    
    def _format_intent_info(self, intent_info: dict) -> str:
        """
        Formatea la informaci√≥n de detecci√≥n de intenci√≥n para presentaci√≥n al usuario.
        
        Esta funci√≥n es esencial para la transparencia del sistema. Cuando un investigador
        hace una pregunta, necesita entender c√≥mo el sistema interpret√≥ su consulta para
        poder evaluar la relevancia de la respuesta y, si es necesario, reformular
        su pregunta de manera m√°s espec√≠fica.
        """
        if not intent_info:
            return ""
        
        intent_type = intent_info.get('detected_intent', 'unknown')
        confidence = intent_info.get('confidence', 0)
        specialized_prompt = intent_info.get('specialized_prompt_used', False)
        processing_time = intent_info.get('processing_time_ms', 0)
        
        # Mapear tipos de intenci√≥n a nombres comprensibles para el usuario
        # Estos nombres est√°n dise√±ados para que investigadores sin conocimiento t√©cnico
        # puedan entender inmediatamente qu√© tipo de respuesta pueden esperar
        intent_names = {
            'definition': 'üìñ Definici√≥n Conceptual',
            'comparison': '‚öñÔ∏è An√°lisis Comparativo', 
            'state_of_art': 'üåü Estado del Arte',
            'gap_analysis': 'üîç An√°lisis de Gaps',
            'unknown': '‚ùì Consulta General',
            'error': '‚ö†Ô∏è Error de Clasificaci√≥n'
        }
        
        intent_name = intent_names.get(intent_type, f'‚ùì {intent_type}')
        
        # Construir mensaje informativo con diferentes niveles de detalle
        info_parts = [f"**Tipo de consulta detectada:** {intent_name}"]
        
        if confidence > 0:
            # Los emojis ayudan a transmitir r√°pidamente el nivel de confianza
            confidence_emoji = "üéØ" if confidence >= 0.8 else "üé≤" if confidence >= 0.6 else "‚ùì"
            info_parts.append(f"**Confianza:** {confidence_emoji} {confidence:.0%}")
        
        if specialized_prompt and intent_type not in ['unknown', 'error']:
            info_parts.append("**Respuesta optimizada:** ‚ú® Usando template acad√©mico especializado")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de an√°lisis:** ‚ö° {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
    
    def _format_expansion_info(self, expansion_info: dict) -> str:
        """
        Formatea la informaci√≥n de expansi√≥n de consulta para mostrar al usuario.
        
        La expansi√≥n de consultas puede ser un concepto abstracto para muchos usuarios.
        Esta funci√≥n hace visible ese proceso, mostrando exactamente qu√© t√©rminos
        adicionales est√° usando el sistema para buscar informaci√≥n relevante.
        Esto ayuda a los investigadores a entender por qu√© ciertos documentos
        aparecieron en los resultados incluso si no conten√≠an exactamente sus t√©rminos originales.
        """
        if not expansion_info or expansion_info.get('expansion_count', 0) == 0:
            return ""
        
        expanded_terms = expansion_info.get('expanded_terms', [])
        processing_time = expansion_info.get('processing_time_ms', 0)
        strategy_used = expansion_info.get('strategy_used', 'unknown')
        
        info_parts = [f"**T√©rminos expandidos:** üîç {', '.join(expanded_terms[:5])}"]
        
        if len(expanded_terms) > 5:
            info_parts.append(f"*... y {len(expanded_terms) - 5} t√©rminos m√°s*")
        
        if strategy_used != 'unknown':
            strategy_names = {
                'conservative': 'Conservadora',
                'moderate': 'Moderada', 
                'comprehensive': 'Comprehensiva'
            }
            strategy_display = strategy_names.get(strategy_used, strategy_used)
            info_parts.append(f"**Estrategia:** üìä {strategy_display}")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de expansi√≥n:** ‚ö° {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
    
    def _format_model_info(self, model_info: dict) -> str:
        """
        Formatea la informaci√≥n del modelo seleccionado para mostrar al usuario.
        
        La selecci√≥n autom√°tica de modelos es una de las caracter√≠sticas m√°s sofisticadas
        del sistema. Esta funci√≥n hace transparente esa decisi√≥n, permitiendo que los
        usuarios entiendan por qu√© el sistema eligi√≥ un modelo particular para su consulta.
        Esto es especialmente importante en contextos acad√©micos donde la reproducibilidad
        y la comprensi√≥n del proceso son fundamentales.
        """
        if not model_info:
            return ""
        
        model_name = model_info.get('selected_model', 'unknown')
        complexity_score = model_info.get('complexity_score', 0)
        reasoning = model_info.get('reasoning', '')
        
        # Mapear modelos t√©cnicos a nombres que los usuarios puedan entender f√°cilmente
        # Incluimos informaci√≥n sobre las fortalezas de cada modelo
        model_names = {
            'gpt-4o': 'üß† GPT-4o (An√°lisis Acad√©mico Profundo)',
            'gpt-4o-mini': '‚ö° GPT-4o-mini (Respuesta R√°pida y Eficiente)',
            'gpt-3.5-turbo': 'üí® GPT-3.5-turbo (Consultas Directas)'
        }
        
        model_display = model_names.get(model_name, f'ü§ñ {model_name}')
        
        info_parts = [f"**Modelo seleccionado:** {model_display}"]
        
        if complexity_score > 0:
            # Visual indicators para el nivel de complejidad detectado
            complexity_emoji = "üî•" if complexity_score >= 0.7 else "‚ö°" if complexity_score >= 0.4 else "üí®"
            info_parts.append(f"**Complejidad detectada:** {complexity_emoji} {complexity_score:.0%}")
        
        # Agregar reasoning si est√° disponible y es informativo
        if reasoning and len(reasoning) < 100:  # Solo mostrar si es conciso
            info_parts.append(f"**Raz√≥n:** {reasoning}")
        
        return "\n".join(info_parts)
    
    def chat_response(self, message: str, history: List[Tuple[str, str]]) -> Tuple[str, str]:
        """
        Procesa las consultas del usuario y genera respuestas con informaci√≥n enriquecida.
        
        Esta es la funci√≥n central que orquesta todo el pipeline RAG avanzado:
        1. Valida el estado del sistema
        2. Procesa la consulta a trav√©s del pipeline completo
        3. Extrae y formatea toda la metadata del proceso
        4. Presenta tanto la respuesta como la informaci√≥n del sistema
        
        El retorno de una tupla permite separar la respuesta principal (que es lo que
        el usuario busca) de la informaci√≥n del sistema (que proporciona transparencia
        sobre c√≥mo se gener√≥ esa respuesta).
        """
        if not self.initialized:
            return "‚ùå El sistema no est√° inicializado. Por favor inicial√≠zalo primero.", ""
        
        if not message.strip():
            return "Por favor, escribe una pregunta acad√©mica.", ""
        
        try:
            # Obtener respuesta completa con toda la metadata del pipeline
            result = self.rag_service.query(message, include_sources=True)
            
            # La respuesta principal es lo que el usuario realmente quiere leer
            main_response = result['answer']
            
            # Construir informaci√≥n del sistema de manera modular
            # Cada secci√≥n proporciona transparencia sobre una parte diferente del proceso
            system_info_parts = []
            
            # Secci√≥n 1: An√°lisis de la consulta (detecci√≥n de intenci√≥n)
            intent_info = result.get('intent_info', {})
            if intent_info:
                intent_details = self._format_intent_info(intent_info)
                if intent_details:
                    system_info_parts.append("### üéØ An√°lisis de Consulta")
                    system_info_parts.append(intent_details)
            
            # Secci√≥n 2: Expansi√≥n de consulta (t√©rminos adicionales utilizados)
            expansion_info = result.get('expansion_info', {})
            if expansion_info and expansion_info.get('expansion_count', 0) > 0:
                expansion_details = self._format_expansion_info(expansion_info)
                if expansion_details:
                    system_info_parts.append("### üîç Expansi√≥n de Consulta")
                    system_info_parts.append(expansion_details)
            
            # Secci√≥n 3: Selecci√≥n de modelo (por qu√© se eligi√≥ este modelo)
            model_info = result.get('model_info', {})
            if model_info:
                model_details = self._format_model_info(model_info)
                if model_details:
                    system_info_parts.append("### ü§ñ Selecci√≥n de Modelo")
                    system_info_parts.append(model_details)
            
            # Secci√≥n 4: Fuentes consultadas (transparencia sobre los documentos utilizados)
            sources = result.get('sources', [])
            if sources:
                system_info_parts.append("### üìö Fuentes Consultadas")
                source_list = []
                for i, source in enumerate(sources[:3], 1):  # Mostrar m√°ximo 3 fuentes principales
                    file_name = source.get('metadata', {}).get('file_name', 'Documento desconocido')
                    source_list.append(f"{i}. **{file_name}**")
                system_info_parts.append("\n".join(source_list))
                
                if len(sources) > 3:
                    system_info_parts.append(f"*... y {len(sources) - 3} fuentes adicionales*")
            
            # Combinar toda la informaci√≥n del sistema en un panel cohesivo
            system_info = "\n\n".join(system_info_parts) if system_info_parts else ""
            
            return main_response, system_info
            
        except Exception as e:
            logger.error(f"Error in chat response: {e}")
            error_msg = f"‚ùå Error al procesar la pregunta: {str(e)}"
            return error_msg, ""
    
    def reindex_documents(self) -> str:
        """
        Reindexar documentos cuando se agregan nuevos archivos o se quiere refrescar la base.
        
        Esta operaci√≥n es costosa en t√©rminos de tiempo y recursos, por lo que incluimos
        advertencias claras y feedback detallado sobre el proceso.
        """
        try:
            count = self.rag_service.reindex_documents()
            if count > 0:
                return f"‚úÖ Reindexados {count} documentos correctamente"
            else:
                return "‚ö†Ô∏è No se encontraron documentos para reindexar"
        except Exception as e:
            logger.error(f"Error reindexing: {e}")
            return f"‚ùå Error al reindexar: {str(e)}"

    def get_faq_markdown(self) -> str:
        """
        Genera contenido din√°mico de preguntas frecuentes basado en el uso real del sistema.
        
        Esta funci√≥n es un ejemplo de c√≥mo el sistema aprende de sus usuarios.
        Las preguntas m√°s frecuentes se pueden usar para mejorar la documentaci√≥n,
        identificar patrones de uso, y optimizar las respuestas del sistema.
        """
        faqs = self.rag_service.get_frequent_questions()
        if not faqs:
            return "_No hay preguntas frecuentes registradas a√∫n._"
        lines = "\n".join(f"- {q}" for q in faqs)
        return f"**Preguntas frecuentes:**\n{lines}"
    
    def create_interface(self) -> gr.Blocks:
        """
        Crea la interfaz de usuario completa con todas las funcionalidades integradas.
        
        Esta funci√≥n construye la interfaz que expone todas las capacidades del sistema
        de manera intuitiva. El dise√±o est√° pensado para investigadores acad√©micos
        que necesitan tanto poder como facilidad de uso.
        """
        with gr.Blocks(
            theme=Soft(),
            css="""
            /* Estilos personalizados para mejorar la experiencia visual */
            .system-info {
                background-color: #f8f9fa !important;
                border: 1px solid #e9ecef !important;
                border-radius: 8px !important;
                padding: 12px !important;
                margin-top: 8px !important;
                font-size: 0.9em !important;
                color: #2c3e50 !important;
            }
            .system-info h3 {
                color: #34495e !important;
                font-weight: bold !important;
                margin-bottom: 8px !important;
            }
            .system-info p {
                color: #2c3e50 !important;
                margin-bottom: 4px !important;
            }
            .system-info strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            /* Indicadores visuales para diferentes tipos de intenci√≥n */
            .intent-indicator {
                display: inline-block !important;
                padding: 4px 8px !important;
                border-radius: 12px !important;
                font-size: 0.8em !important;
                font-weight: bold !important;
                margin-right: 8px !important;
            }
            .definition { 
                background-color: #e3f2fd !important; 
                color: #1565c0 !important; 
            }
            .comparison { 
                background-color: #f3e5f5 !important; 
                color: #7b1fa2 !important; 
            }
            .state_of_art { 
                background-color: #e8f5e8 !important; 
                color: #2e7d32 !important; 
            }
            .gap_analysis { 
                background-color: #fff3e0 !important; 
                color: #ef6c00 !important; 
            }
            /* Asegurar legibilidad en el panel lateral */
            .gr-column .gr-markdown {
                color: #2c3e50 !important;
            }
            .gr-column .gr-markdown h3 {
                color: #34495e !important;
                font-weight: bold !important;
            }
            .gr-column .gr-markdown strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            """
        ) as interface:
            
            # Header principal con branding y descripci√≥n del sistema
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 2rem;">
                <h1>ü§ñ Sistema RAG Avanzado para Investigaci√≥n Acad√©mica</h1>
                <p>Especializado en IA para Historias de Usuario - Con Inteligencia Artificial Multicapa</p>
                <p><small>
                    üéØ Detecci√≥n autom√°tica de intenci√≥n &nbsp;‚Ä¢&nbsp; 
                    üîç Expansi√≥n inteligente de consultas &nbsp;‚Ä¢&nbsp; 
                    ü§ñ Selecci√≥n din√°mica de modelos &nbsp;‚Ä¢&nbsp; 
                    üìä Transparencia completa del proceso
                </small></p>
            </div>
            """)
            
            with gr.Tabs():
                # Tab principal - Chat Acad√©mico Inteligente
                with gr.TabItem("üí¨ Chat Acad√©mico Inteligente"):
                    gr.Markdown("### Asistente de Investigaci√≥n con IA Multicapa")
                    gr.Markdown("""
                    Haz preguntas acad√©micas y observa c√≥mo el sistema combina m√∫ltiples t√©cnicas de IA:
                    - üéØ **Detecta autom√°ticamente** el tipo de consulta (definici√≥n, comparaci√≥n, estado del arte, gaps)
                    - üîç **Expande tu consulta** con sin√≥nimos acad√©micos y t√©rminos relacionados relevantes  
                    - ü§ñ **Selecciona el modelo apropiado** (GPT-4o para an√°lisis complejos, GPT-4o-mini para consultas simples)  
                    - ‚ú® **Optimiza la respuesta** usando templates acad√©micos especializados por tipo de intenci√≥n
                    - üìä **Muestra todo el proceso** para transparencia y reproducibilidad acad√©mica
                    """)
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            # √Årea principal de conversaci√≥n
                            chatbot = gr.Chatbot(
                                label="Conversaci√≥n Acad√©mica Inteligente",
                                height=500,
                                type='messages',
                                show_label=True
                            )
                            
                            with gr.Row():
                                msg = gr.Textbox(
                                    label="Tu pregunta de investigaci√≥n",
                                    placeholder="Ej: Compare las metodolog√≠as de IA para historias de usuario...",
                                    scale=4,
                                    lines=2
                                )
                                send_btn = gr.Button("Enviar", variant="primary", scale=1)
                            
                            with gr.Row():
                                clear_btn = gr.Button("üóëÔ∏è Limpiar Chat", variant="secondary")
                        
                        with gr.Column(scale=1):
                            # Panel de informaci√≥n del sistema - la clave de la transparencia
                            system_info_display = gr.Markdown(
                                label="üìä Informaci√≥n del Sistema",
                                value="*Env√≠a una consulta para ver c√≥mo el sistema analiza tu pregunta con IA multicapa*",
                                elem_classes=["system-info"],
                                visible=True
                            )
                    
                    # Ejemplos acad√©micos organizados por tipo para educar al usuario
                    with gr.Accordion("üìã Ejemplos por Tipo de Consulta", open=False):
                        gr.Markdown("""
                        **üîµ Definiciones Conceptuales (Activar√° template especializado en definiciones):**
                        - "¬øQu√© es Natural Language Processing en requirements engineering?"
                        - "Define machine learning aplicado a historias de usuario"
                        - "Explica el concepto de automated requirements generation"
                        
                        **üü£ An√°lisis Comparativos (Activar√° template de comparaci√≥n sistem√°tica):**
                        - "Compara supervised vs unsupervised learning para user stories"
                        - "Diferencias entre rule-based y ML approaches en requirements"
                        - "Ventajas y desventajas de BERT vs GPT para an√°lisis de texto"
                        
                        **üü¢ Estado del Arte (Activar√° template de s√≠ntesis temporal):**
                        - "Estado del arte en IA para automatizaci√≥n de requirements"
                        - "Enfoques actuales en NLP para historias de usuario"
                        - "Tendencias recientes en AI-assisted software development"
                        
                        **üü† An√°lisis de Gaps (Activar√° template de identificaci√≥n de oportunidades):**
                        - "¬øQu√© limitaciones tienen los m√©todos actuales de NLP para user stories?"
                        - "Gaps de investigaci√≥n en automated requirements engineering"
                        - "¬øQu√© oportunidades existen para mejorar las t√©cnicas actuales?"
                        """)

                    # FAQ din√°micas - aprendizaje del sistema
                    faq_display = gr.Markdown(value=self.get_faq_markdown())
                    
                    def respond(message, chat_history):
                        """
                        Handler principal para las respuestas del chat.
                        
                        Esta funci√≥n coordina todo el proceso de respuesta y actualiza
                        tanto el historial de chat como la informaci√≥n del sistema.
                        """
                        if not message.strip():
                            return chat_history, "", self.get_faq_markdown(), ""
                        
                        # Procesar la consulta a trav√©s del pipeline completo
                        bot_response, system_info = self.chat_response(message, chat_history)
                        
                        # Actualizar historial en formato compatible con Gradio
                        chat_history.append({"role": "user", "content": message})
                        chat_history.append({"role": "assistant", "content": bot_response})

                        return chat_history, "", self.get_faq_markdown(), system_info
                    
                    # Event handlers para interacci√≥n del usuario
                    send_btn.click(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    msg.submit(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    clear_btn.click(
                        lambda: ([], "", self.get_faq_markdown(), "*Env√≠a una consulta para ver el an√°lisis multicapa del sistema*"),
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                
                # Tab de administraci√≥n del sistema
                with gr.TabItem("‚öôÔ∏è Administraci√≥n del Sistema"):
                    gr.Markdown("### Gesti√≥n del Sistema RAG Inteligente")
                    
                    with gr.Row():
                        init_btn = gr.Button("üöÄ Inicializar Sistema", variant="primary")
                        reindex_btn = gr.Button("üìö Reindexar Documentos", variant="secondary")
                    
                    status_output = gr.Textbox(
                        label="Estado del Sistema",
                        interactive=False,
                        lines=3
                    )
                    
                    # Informaci√≥n detallada de configuraci√≥n para transparency t√©cnica
                    gr.Markdown("### Configuraci√≥n del Sistema RAG Inteligente")
                    gr.Markdown(f"""
                    **üß† Detecci√≥n de Intenci√≥n Acad√©mica:**
                    - üéØ **Estado**: `{'Habilitada' if settings.enable_intent_detection else 'Deshabilitada'}`
                    - üìä **Umbral de confianza**: `{settings.intent_confidence_threshold}`
                    - ‚ö° **Tiempo m√°ximo de procesamiento**: `{settings.intent_max_processing_time_ms}ms`
                    
                    **üîç Expansi√≥n Inteligente de Consultas:**
                    - üéØ **Estado**: `{'Habilitada' if settings.enable_query_expansion else 'Deshabilitada'}`
                    - üìä **M√°ximo t√©rminos expandidos**: `{settings.max_expansion_terms}`
                    - üé® **Estrategia de expansi√≥n**: `{settings.expansion_strategy}`
                    - ‚ö° **Tiempo m√°ximo de procesamiento**: `{settings.expansion_max_processing_time_ms}ms`
                    
                    **ü§ñ Selecci√≥n Inteligente de Modelos:**
                    - üß† **Modelo para consultas complejas**: `{settings.complex_model}`
                    - ‚ö° **Modelo para consultas simples**: `{settings.simple_model}`
                    - üéØ **Umbral de complejidad**: `{settings.complexity_threshold}`
                    - üîÑ **Selecci√≥n autom√°tica**: `{'Activada' if settings.enable_smart_selection else 'Desactivada'}`
                    
                    **üìö Configuraci√≥n RAG Base:**
                    - üìÅ **Directorio de documentos**: `{settings.documents_path}`
                    - üóÉÔ∏è **Base de datos vectorial**: `{settings.vector_db_path}`
                    - üî§ **Modelo de embeddings**: `{settings.embedding_model}`
                    - üìä **Tama√±o de chunk**: `{settings.chunk_size}`
                    - üîó **Overlap de chunk**: `{settings.chunk_overlap}`
                    - üìñ **Documentos por consulta**: `{settings.max_documents}`
                    """)
                
                # Tab de gu√≠a acad√©mica - educaci√≥n del usuario
                with gr.TabItem("üìö Gu√≠a de Investigaci√≥n Inteligente"):
                    gr.Markdown("""
                    ## üéì Sistema RAG Inteligente para Investigaci√≥n Acad√©mica
                    
                    ### üß† Inteligencia Artificial Multicapa
                    
                    Este sistema combina **cuatro niveles de IA** para optimizar tu experiencia de investigaci√≥n:
                    
                    #### üéØ **Nivel 1: Detecci√≥n Autom√°tica de Intenci√≥n**
                    El sistema analiza tu consulta en **menos de 200ms** para determinar qu√© tipo de respuesta necesitas:
                    
                    - **üìñ Definici√≥n Conceptual** ‚Üí Estructura la respuesta con definici√≥n formal, contexto hist√≥rico y aplicaciones
                    - **‚öñÔ∏è An√°lisis Comparativo** ‚Üí Organiza la informaci√≥n en an√°lisis sistem√°tico y tablas comparativas  
                    - **üåü Estado del Arte** ‚Üí Presenta cronolog√≠a, tendencias actuales y consenso acad√©mico
                    - **üîç An√°lisis de Gaps** ‚Üí Identifica limitaciones, oportunidades y direcciones futuras
                    
                    #### üîç **Nivel 2: Expansi√≥n Inteligente de Consulta**
                    Basado en tu intenci√≥n detectada, expande autom√°ticamente tu consulta:
                    
                    - **Sin√≥nimos acad√©micos** ‚Üí "machine learning" se expande a "ML", "AI", "predictive modeling"
                    - **T√©rminos relacionados** ‚Üí "user stories" incluye "acceptance criteria", "requirements"
                    - **Variaciones contextuales** ‚Üí Adaptadas al tipo de consulta espec√≠fica
                    
                    #### ü§ñ **Nivel 3: Selecci√≥n Inteligente de Modelo**
                    Basado en la complejidad de tu consulta expandida, elige autom√°ticamente:
                    
                    - **üß† GPT-4o** para an√°lisis acad√©micos complejos, comparaciones metodol√≥gicas y s√≠ntesis profundas
                    - **‚ö° GPT-4o-mini** para definiciones claras, consultas directas y respuestas r√°pidas
                    
                    #### ‚ú® **Nivel 4: Optimizaci√≥n de Template**
                    Usando tu intenci√≥n detectada, aplica templates acad√©micos especializados:
                    
                    - **Estructura acad√©mica apropiada** para cada tipo de consulta
                    - **Enfoque metodol√≥gico espec√≠fico** (cronol√≥gico, comparativo, anal√≠tico)
                    - **Formato optimizado** para tu contexto de investigaci√≥n
                    
                    ### üöÄ C√≥mo Aprovechar al M√°ximo el Sistema
                    
                    #### **Para Investigaci√≥n de Tesis sobre IA y User Stories:**
                    
                    **üîç Exploraci√≥n Inicial:**
                    1. "Estado del arte en IA para historias de usuario" (activar√° an√°lisis cronol√≥gico con expansi√≥n temporal)
                    2. "¬øQu√© es automated requirements generation?" (activar√° definici√≥n estructurada con sin√≥nimos t√©cnicos)
                    
                    **üìä An√°lisis Comparativo:**
                    1. "Compara NLP vs Machine Learning para requirements analysis" (expandir√° con variaciones metodol√≥gicas)
                    2. "Ventajas y desventajas de rule-based vs deep learning approaches" (incluir√° t√©rminos contrastivos)
                    
                    **üéØ Identificaci√≥n de Oportunidades:**
                    1. "¬øQu√© limitaciones tienen las t√©cnicas actuales de NLP para user stories?" (expandir√° con t√©rminos de gap analysis)
                    2. "Gaps de investigaci√≥n en automated requirements engineering" (incluir√° sin√≥nimos de limitaciones)
                    
                    ### üí° Indicadores Visuales del Sistema
                    
                    Observa el **panel lateral** durante tus consultas para ver:
                    
                    - **üéØ Tipo de consulta detectada** con nivel de confianza y reasoning
- **üîç T√©rminos expandidos** agregados autom√°ticamente con estrategia utilizada
                   - **ü§ñ Modelo seleccionado** y raz√≥n de la selecci√≥n basada en complejidad  
                   - **‚ú® Optimizaci√≥n aplicada** (si usa template especializado)
                   - **üìö Fuentes consultadas** para tu respuesta espec√≠fica
                    
                   ### üéì Resultados de Investigaci√≥n Optimizados
                    
                   **Para Definiciones:**
                   - Estructura acad√©mica formal con contexto hist√≥rico
                   - Referencias a autores principales y papers fundamentales
                   - Conexiones con conceptos relacionados
                   - Expansi√≥n autom√°tica con sin√≥nimos t√©cnicos y variaciones
                    
                   **Para Comparaciones:**
                   - Matrices comparativas sistem√°ticas
                   - An√°lisis de ventajas/desventajas equilibrado
                   - Recomendaciones basadas en contexto de uso
                   - T√©rminos contrastivos agregados autom√°ticamente
                    
                   **Para Estado del Arte:**
                   - Evoluci√≥n temporal de enfoques
                   - Identificaci√≥n de tendencias emergentes  
                   - An√°lisis de consenso vs controversias
                   - Expansi√≥n con indicadores temporales y de tendencia
                    
                   **Para An√°lisis de Gaps:**
                   - Categorizaci√≥n de limitaciones por tipo
                   - Oportunidades espec√≠ficas de investigaci√≥n
                   - Conexi√≥n con trabajos futuros sugeridos
                   - T√©rminos de limitaci√≥n y oportunidad expandidos
                    
                   ### üî¨ Optimizaci√≥n para tu Dominio Espec√≠fico
                   
                   El sistema est√° **pre-optimizado** para investigaci√≥n en:
                   - ‚úÖ Inteligencia Artificial aplicada a Software Engineering
                   - ‚úÖ Natural Language Processing para Requirements  
                   - ‚úÖ Machine Learning en User Story Analysis
                   - ‚úÖ Automated Software Development Tools
                   - ‚úÖ AI-Assisted Development Methodologies
                    
                   ### üìà Consejos para Consultas de Alta Calidad
                   
                   **üéØ S√© espec√≠fico en tu intenci√≥n:**
                   - ‚ùå "machine learning" 
                   - ‚úÖ "¬øQu√© t√©cnicas de machine learning se usan para analizar historias de usuario?"
                   - üîç *El sistema expandir√° autom√°ticamente con t√©rminos relacionados*
                    
                   **üîó Conecta conceptos:**
                   - ‚ùå "NLP tools"
                   - ‚úÖ "Compare herramientas de NLP para extracci√≥n autom√°tica de requirements"
                   - üîç *Activar√° template comparativo y expandir√° con variaciones t√©cnicas*
                    
                   **üìä Solicita an√°lisis estructurado:**
                   - ‚ùå "research gaps"
                   - ‚úÖ "¬øQu√© limitaciones identifican los estudios actuales en automated user story generation?"
                   - üîç *Detectar√° gap analysis y expandir√° con sin√≥nimos de limitaciones*
                    
                   ### üöÄ El Futuro de tu Investigaci√≥n
                   
                   Con este sistema inteligente multicapa, puedes:
                   - **‚ö° Acelerar** tu revisi√≥n de literatura 5-10x con expansi√≥n autom√°tica
                   - **üéØ Identificar** gaps de investigaci√≥n autom√°ticamente con detecci√≥n de intenci√≥n  
                   - **üìä Comparar** metodolog√≠as de manera sistem√°tica con templates especializados
                   - **üîç Descubrir** conexiones entre diferentes l√≠neas de investigaci√≥n mediante expansi√≥n sem√°ntica
                   - **üìà Optimizar** la calidad acad√©mica con selecci√≥n inteligente de modelos
                   - **üî¨ Reproducir** resultados con total transparencia del proceso
                   """)
           
           # Event handlers para funcionalidades administrativas
            init_btn.click(
                fn=self.initialize_service,
                outputs=status_output
            )
            
            reindex_btn.click(
                fn=self.reindex_documents,
                outputs=status_output
            )
        
        return interface

    def launch(self, **kwargs):
        """
        Lanza la aplicaci√≥n con configuraci√≥n optimizada para investigaci√≥n acad√©mica.
        
        Esta funci√≥n inicia el servidor web que expone toda la funcionalidad del sistema
        RAG inteligente. La configuraci√≥n por defecto est√° optimizada para uso acad√©mico.
        """
        interface = self.create_interface()
        
        # Configuraci√≥n por defecto optimizada
        launch_kwargs = {
            'server_port': settings.server_port,
            'share': settings.share_gradio,
            'show_error': True,
            'quiet': False,
            **kwargs
        }
        
        logger.info(f"Launching advanced RAG app with multicapa AI on port {launch_kwargs['server_port']}")
        logger.info("Features enabled: Intent Detection + Query Expansion + Smart Model Selection")
        interface.launch(**launch_kwargs)