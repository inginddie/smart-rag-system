# -*- coding: utf-8 -*-
import gradio as gr
from typing import List, Tuple
from src.services.rag_service import RAGService
from src.utils.logger import setup_logger
from config.settings import settings

logger = setup_logger()

class GradioRAGApp:
    """Aplicaci√≥n Gradio para el sistema RAG con selecci√≥n inteligente de modelos"""
    
    def __init__(self):
        self.rag_service = RAGService()
        self.initialized = False
    
    def initialize_service(self) -> str:
        """Inicializa el servicio RAG"""
        try:
            if self.rag_service.initialize():
                self.initialized = True
                return "‚úÖ Sistema RAG inicializado correctamente con selecci√≥n inteligente de modelos"
            else:
                return "‚ö†Ô∏è Sistema inicializado pero no se encontraron documentos para indexar"
        except Exception as e:
            logger.error(f"Error initializing service: {e}")
            return f"‚ùå Error al inicializar: {str(e)}"
    
    def chat_response(self, message: str, history: List[Tuple[str, str]]) -> str:
        """Maneja las respuestas del chat con selecci√≥n inteligente de modelos"""
        if not self.initialized:
            return "‚ùå El sistema no est√° inicializado. Por favor inicial√≠zalo primero."
        
        if not message.strip():
            return "Por favor, escribe una pregunta."
        
        try:
            # Obtener respuesta con informaci√≥n del modelo
            result = self.rag_service.query(message)
            response = result['answer']
            
            # Agregar informaci√≥n del modelo usado (opcional, para debugging)
            model_info = result.get('model_info', {})
            if model_info and settings.log_level == "DEBUG":
                model_name = model_info.get('selected_model', 'unknown')
                complexity = model_info.get('complexity_score', 0)
                response += f"\n\n*[Procesado con {model_name}, complejidad: {complexity:.2f}]*"
            
            return response
            
        except Exception as e:
            logger.error(f"Error in chat response: {e}")
            return f"‚ùå Error al procesar la pregunta: {str(e)}"
    
    def reindex_documents(self) -> str:
        """Reindexar documentos"""
        try:
            count = self.rag_service.reindex_documents()
            if count > 0:
                return f"‚úÖ Reindexados {count} documentos correctamente"
            else:
                return "‚ö†Ô∏è No se encontraron documentos para reindexar"
        except Exception as e:
            logger.error(f"Error reindexing: {e}")
            return f"‚ùå Error al reindexar: {str(e)}"

    def get_faq_markdown(self) -> str:
        """Genera el texto Markdown de las preguntas frecuentes."""
        faqs = self.rag_service.get_frequent_questions()
        if not faqs:
            return "_No hay preguntas frecuentes registradas a√∫n._"
        lines = "\n".join(f"- {q}" for q in faqs)
        return f"**Preguntas frecuentes:**\n{lines}"
    
    def get_total_documents(self) -> int:
        """Obtiene el n√∫mero total de documentos procesados"""
        try:
            return self.rag_service.get_total_documents_processed()
        except Exception as e:
            logger.error(f"Error obteniendo total de documentos: {e}")
            return 0

    def create_interface(self) -> gr.Blocks:
        """Crea la interfaz de Gradio actualizada"""
        with gr.Blocks(
            title="Sistema RAG Avanzado - Investigaci√≥n de Tesis",
            theme=gr.themes.Soft(),
        ) as interface:
            
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 2rem;">
                <h1>ü§ñ Sistema RAG Avanzado para Investigaci√≥n</h1>
                <p>Especializado en IA para Historias de Usuario - Selecci√≥n Inteligente de Modelos</p>
                <p><small>Usa autom√°ticamente GPT-4o para an√°lisis complejos y GPT-4o-mini para consultas simples</small></p>
            </div>
            """)
            
            with gr.Tabs():
                # Tab principal - Chat
                with gr.TabItem("üí¨ Chat Acad√©mico"):
                    gr.Markdown("### Asistente de Investigaci√≥n")
                    gr.Markdown("Haz preguntas acad√©micas sobre tus documentos. El sistema seleccionar√° autom√°ticamente el modelo m√°s apropiado.")
                    
                    # ChatInterface actualizado para nueva versi√≥n de Gradio
                    chatbot = gr.Chatbot(
                        label="Conversaci√≥n Acad√©mica",
                        height=400,
                        type='messages'  # Corregir warning de Gradio
                    )
                    
                    with gr.Row():
                        msg = gr.Textbox(
                            label="Tu pregunta de investigaci√≥n",
                            placeholder="Ej: Compara las metodolog√≠as de IA para historias de usuario...",
                            scale=4
                        )
                        send_btn = gr.Button("Enviar", variant="primary", scale=1)
                    
                    with gr.Row():
                        clear_btn = gr.Button("üóëÔ∏è Limpiar Chat", variant="secondary")
                    
                    # Ejemplos acad√©micos espec√≠ficos para tu investigaci√≥n
                    gr.Examples(
                        examples=[
                            "¬øCu√°les son las principales metodolog√≠as de IA para mejorar historias de usuario?",
                            "Compara los enfoques de NLP vs Machine Learning en requirements engineering",
                            "¬øQu√© gaps de investigaci√≥n existen en la automatizaci√≥n de historias de usuario?",
                            "Analiza las m√©tricas de evaluaci√≥n utilizadas en la literatura",
                            "¬øQu√© t√©cnicas de deep learning se han aplicado a requirements?",
                            "Resume el estado del arte en IA para desarrollo √°gil",
                        ],
                        inputs=msg
                    )

                    faq_display = gr.Markdown(value=self.get_faq_markdown())
                    
                    def respond(message, chat_history):
                        if not message.strip():
                            return chat_history, "", self.get_faq_markdown()
                        
                        # Obtener respuesta del RAG
                        bot_response = self.chat_response(message, chat_history)
                        
                        # Agregar al historial en formato correcto para Gradio
                        chat_history.append({"role": "user", "content": message})
                        chat_history.append({"role": "assistant", "content": bot_response})

                        return chat_history, "", self.get_faq_markdown()
                    
                    # Event handlers para el chat
                    send_btn.click(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display]
                    )
                    
                    msg.submit(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display]
                    )
                    
                    clear_btn.click(
                        lambda: ([], "", self.get_faq_markdown()),
                        outputs=[chatbot, msg, faq_display]
                    )
                
                # Tab de administraci√≥n
                with gr.TabItem("‚öôÔ∏è Administraci√≥n"):
                    gr.Markdown("### Gesti√≥n del Sistema RAG")
                    
                    with gr.Row():
                        init_btn = gr.Button("üöÄ Inicializar Sistema", variant="primary")
                        reindex_btn = gr.Button("üìö Reindexar Documentos", variant="secondary")
                    
                    status_output = gr.Textbox(
                        label="Estado del Sistema",
                        interactive=False,
                        lines=3
                    )
                    
                    # Informaci√≥n del sistema
                    gr.Markdown("### Configuraci√≥n Actual")
                    gr.Markdown(f"""
                    **Selecci√≥n Inteligente de Modelos:**
                    - üß† **Modelo para consultas complejas**: `{settings.complex_model}`
                    - ‚ö° **Modelo para consultas simples**: `{settings.simple_model}`
                    - üéØ **Umbral de complejidad**: `{settings.complexity_threshold}`
                    - üîÑ **Selecci√≥n autom√°tica**: `{'Activada' if settings.enable_smart_selection else 'Desactivada'}`
                    
                    **Configuraci√≥n RAG:**
                    - üìÅ **Directorio de documentos**: `{settings.documents_path}`
                    - üóÉÔ∏è **Base de datos vectorial**: `{settings.vector_db_path}`
                    - üî§ **Modelo de embeddings**: `{settings.embedding_model}`
                    - üìä **Tama√±o de chunk**: `{settings.chunk_size}`
                    - üîó **Overlap de chunk**: `{settings.chunk_overlap}`
                    - üìñ **Documentos por consulta**: `{settings.max_documents}`
                    """)
                
                # Tab de ayuda acad√©mica
                with gr.TabItem("üìö Gu√≠a de Investigaci√≥n"):
                    gr.Markdown("""
                    ## üéì Sistema RAG para Investigaci√≥n de Tesis
                    
                    ### üß† Selecci√≥n Inteligente de Modelos
                    
                    El sistema **selecciona autom√°ticamente** el modelo m√°s apropiado:
                    
                    **GPT-4o (An√°lisis Complejo)** se activa con:
                    - üî¨ **Palabras acad√©micas**: "analiza", "compara", "eval√∫a", "metodolog√≠a"
                    - üìä **An√°lisis cr√≠tico**: "ventajas y desventajas", "limitaciones", "gaps"
                    - üéØ **Estado del arte**: "literatura", "s√≠ntesis", "framework"
                    - üìù **Investigaci√≥n**: "paper", "estudio", "hallazgos"
                    
                    **GPT-4o-mini (Consultas Simples)** para:
                    - ‚ùì **Definiciones**: "¬øQu√© es...?", "Define..."
                    - üìã **Listas**: "Lista las t√©cnicas...", "Enumera..."
                    - üîç **B√∫squedas b√°sicas**: "Encuentra...", "Busca..."
                    
                    ### üöÄ Tipos de Consultas para tu Tesis
                    
                    #### **Estado del Arte** (‚Üí GPT-4o)
                    - "Analiza el estado del arte en IA para historias de usuario"
                    - "¬øCu√°les son las metodolog√≠as principales en la literatura?"
                    - "Sintetiza los enfoques de NLP en requirements engineering"
                    
                    #### **Comparaciones Metodol√≥gicas** (‚Üí GPT-4o)
                    - "Compara los frameworks de Chen et al. vs Smith et al."
                    - "¬øCu√°les son las ventajas y desventajas de cada enfoque?"
                    - "Eval√∫a cr√≠ticamente las t√©cnicas de machine learning aplicadas"
                    
                    #### **Gaps de Investigaci√≥n** (‚Üí GPT-4o)
                    - "¬øQu√© limitaciones identifican los estudios actuales?"
                    - "¬øD√≥nde est√°n los gaps en la automatizaci√≥n de requirements?"
                    - "¬øQu√© direcciones futuras sugiere la literatura?"
                    
                    #### **Consultas Espec√≠ficas** (‚Üí GPT-4o-mini)
                    - "¬øQu√© es una historia de usuario?"
                    - "Lista las t√©cnicas de NLP mencionadas"
                    - "Define requirements engineering"
                    
                    ### üí° Consejos para Mejores Resultados
                    
                    1. **S√© espec√≠fico** en tus preguntas acad√©micas
                    2. **Usa terminolog√≠a t√©cnica** para activar an√°lisis profundo
                    3. **Pregunta por comparaciones** para obtener s√≠ntesis complejas
                    4. **Solicita gaps** para identificar oportunidades de investigaci√≥n
                    5. **Pide citas espec√≠ficas** mencionando autores cuando sea posible
                    
                    ### üìñ Preparaci√≥n de Documentos
                    
                    1. **Organiza tus 159 PDFs** por categor√≠as tem√°ticas
                    2. **Procesa por lotes** (20-30 papers a la vez)
                    3. **Verifica nombres** descriptivos de archivos
                    4. **Inicia con papers fundamentales** antes de casos espec√≠ficos
                    """)
                
                # Tab de estado del sistema
                with gr.TabItem("üìä Estado del Sistema"):
                    gr.Markdown("### Resumen del Estado Actual del Sistema RAG")
                    document_count_display = gr.Textbox(label="N√∫mero total de documentos procesados", interactive=False)
                    refresh_btn = gr.Button("Actualizar")

                    refresh_btn.click(
                        fn=self.get_total_documents,
                        inputs=None,
                        outputs=document_count_display
                    )
        
        return interface
    
    def launch(self, **kwargs):
        """Lanza la aplicaci√≥n"""
        interface = self.create_interface()
        
        # Configuraci√≥n por defecto
        launch_kwargs = {
            'server_port': settings.server_port,
            'share': settings.share_gradio,
            'show_error': True,
            'quiet': False,
            **kwargs
        }
        
        logger.info(f"Launching RAG app with smart model selection on port {launch_kwargs['server_port']}")
        interface.launch(**launch_kwargs)

import React from 'react';
import DocumentCountPanel from './components/DocumentCountPanel';

// Funci√≥n simulada para obtener el n√∫mero de documentos procesados
const fetchDocumentCount = async () => {
  // Aqu√≠ se debe llamar al backend real para obtener el dato
  return 123; // Valor simulado
};

const App = () => {
  return (
    <div>
      <h1>Sistema RAG - Panel Principal</h1>
      <DocumentCountPanel fetchDocumentCount={fetchDocumentCount} />
      {/* Otros componentes y funcionalidades del frontend */}
    </div>
  );
};

export default App;