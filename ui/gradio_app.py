# -*- coding: utf-8 -*-
import gradio as gr
from typing import List, Tuple
from src.services.rag_service import RAGService
from src.utils.logger import setup_logger
from config.settings import settings

logger = setup_logger()

class GradioRAGApp:
    """AplicaciÃ³n Gradio para el sistema RAG con selecciÃ³n inteligente de modelos y detecciÃ³n de intenciÃ³n acadÃ©mica"""
    
    def __init__(self):
        self.rag_service = RAGService()
        self.initialized = False
    
    def initialize_service(self) -> str:
        """Inicializa el servicio RAG"""
        try:
            if self.rag_service.initialize():
                self.initialized = True
                return "âœ… Sistema RAG inicializado correctamente con detecciÃ³n de intenciÃ³n acadÃ©mica habilitada"
            else:
                return "âš ï¸ Sistema inicializado pero no se encontraron documentos para indexar"
        except Exception as e:
            logger.error(f"Error initializing service: {e}")
            return f"âŒ Error al inicializar: {str(e)}"
    
    def _format_intent_info(self, intent_info: dict) -> str:
        """Formatea la informaciÃ³n de intenciÃ³n para mostrar al usuario"""
        if not intent_info:
            return ""
        
        intent_type = intent_info.get('detected_intent', 'unknown')
        confidence = intent_info.get('confidence', 0)
        specialized_prompt = intent_info.get('specialized_prompt_used', False)
        processing_time = intent_info.get('processing_time_ms', 0)
        
        # Mapear tipos de intenciÃ³n a nombres amigables
        intent_names = {
            'definition': 'ğŸ“– DefiniciÃ³n Conceptual',
            'comparison': 'âš–ï¸ AnÃ¡lisis Comparativo', 
            'state_of_art': 'ğŸŒŸ Estado del Arte',
            'gap_analysis': 'ğŸ” AnÃ¡lisis de Gaps',
            'unknown': 'â“ Consulta General',
            'error': 'âš ï¸ Error de ClasificaciÃ³n'
        }
        
        intent_name = intent_names.get(intent_type, f'â“ {intent_type}')
        
        # Crear mensaje informativo
        info_parts = [f"**Tipo de consulta detectada:** {intent_name}"]
        
        if confidence > 0:
            confidence_emoji = "ğŸ¯" if confidence >= 0.8 else "ğŸ²" if confidence >= 0.6 else "â“"
            info_parts.append(f"**Confianza:** {confidence_emoji} {confidence:.0%}")
        
        if specialized_prompt and intent_type not in ['unknown', 'error']:
            info_parts.append("**Respuesta optimizada:** âœ¨ Usando template acadÃ©mico especializado")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de anÃ¡lisis:** âš¡ {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
    
    def _format_expansion_info(self, expansion_info: dict) -> str:
        """Formatea la informaciÃ³n de expansiÃ³n de consulta para mostrar al usuario"""
        if not expansion_info or expansion_info.get('expansion_count', 0) == 0:
            return ""
        
        expanded_terms = expansion_info.get('expanded_terms', [])
        processing_time = expansion_info.get('processing_time_ms', 0)
        
        info_parts = [f"**TÃ©rminos expandidos:** ğŸ” {', '.join(expanded_terms[:5])}"]
        
        if len(expanded_terms) > 5:
            info_parts.append(f"*... y {len(expanded_terms) - 5} tÃ©rminos mÃ¡s*")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de expansiÃ³n:** âš¡ {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
        """Formatea la informaciÃ³n del modelo para mostrar al usuario"""
        if not model_info:
            return ""
        
        model_name = model_info.get('selected_model', 'unknown')
        complexity_score = model_info.get('complexity_score', 0)
        
        # Mapear modelos a nombres amigables
        model_names = {
            'gpt-4o': 'ğŸ§  GPT-4o (AnÃ¡lisis Complejo)',
            'gpt-4o-mini': 'âš¡ GPT-4o-mini (Respuesta RÃ¡pida)',
            'gpt-3.5-turbo': 'ğŸ’¨ GPT-3.5-turbo (Eficiente)'
        }
        
        model_display = model_names.get(model_name, f'ğŸ¤– {model_name}')
        
        info_parts = [f"**Modelo seleccionado:** {model_display}"]
        
        if complexity_score > 0:
            complexity_emoji = "ğŸ”¥" if complexity_score >= 0.7 else "âš¡" if complexity_score >= 0.4 else "ğŸ’¨"
            info_parts.append(f"**Complejidad detectada:** {complexity_emoji} {complexity_score:.0%}")
        
        return "\n".join(info_parts)
    
    def chat_response(self, message: str, history: List[Tuple[str, str]]) -> Tuple[str, str]:
        """
        Maneja las respuestas del chat con informaciÃ³n enriquecida de intenciÃ³n y modelo
        
        Returns:
            Tuple[respuesta_principal, informaciÃ³n_del_sistema]
        """
        if not self.initialized:
            return "âŒ El sistema no estÃ¡ inicializado. Por favor inicialÃ­zalo primero.", ""
        
        if not message.strip():
            return "Por favor, escribe una pregunta.", ""
        
        try:
            # Obtener respuesta completa con metadata
            result = self.rag_service.query(message, include_sources=True)
            
            # Respuesta principal
            main_response = result['answer']
            
            # InformaciÃ³n del sistema (intent + model + expansion)
            system_info_parts = []
            
            # Agregar informaciÃ³n de intenciÃ³n si estÃ¡ disponible
            intent_info = result.get('intent_info', {})
            if intent_info:
                intent_details = self._format_intent_info(intent_info)
                if intent_details:
                    system_info_parts.append("### ğŸ¯ AnÃ¡lisis de Consulta")
                    system_info_parts.append(intent_details)
            
            # Agregar informaciÃ³n de expansiÃ³n si estÃ¡ disponible
            expansion_info = result.get('expansion_info', {})
            if expansion_info:
                expansion_details = self._format_expansion_info(expansion_info)
                if expansion_details:
                    system_info_parts.append("### ğŸ” ExpansiÃ³n de Consulta")
                    system_info_parts.append(expansion_details)
            
            # Agregar informaciÃ³n del modelo si estÃ¡ disponible
            model_info = result.get('model_info', {})
            if model_info:
                model_details = self._format_model_info(model_info)
                if model_details:
                    system_info_parts.append("### ğŸ¤– SelecciÃ³n de Modelo")
                    system_info_parts.append(model_details)
            
            # Agregar informaciÃ³n de fuentes si estÃ¡ disponible
            sources = result.get('sources', [])
            if sources:
                system_info_parts.append("### ğŸ“š Fuentes Consultadas")
                source_list = []
                for i, source in enumerate(sources[:3], 1):  # Mostrar mÃ¡ximo 3 fuentes
                    file_name = source.get('metadata', {}).get('file_name', 'Documento desconocido')
                    source_list.append(f"{i}. **{file_name}**")
                system_info_parts.append("\n".join(source_list))
                
                if len(sources) > 3:
                    system_info_parts.append(f"*... y {len(sources) - 3} fuentes adicionales*")
            
            # Combinar informaciÃ³n del sistema
            system_info = "\n\n".join(system_info_parts) if system_info_parts else ""
            
            return main_response, system_info
            
        except Exception as e:
            logger.error(f"Error in chat response: {e}")
            error_msg = f"âŒ Error al procesar la pregunta: {str(e)}"
            return error_msg, ""
    
    def reindex_documents(self) -> str:
        """Reindexar documentos"""
        try:
            count = self.rag_service.reindex_documents()
            if count > 0:
                return f"âœ… Reindexados {count} documentos correctamente"
            else:
                return "âš ï¸ No se encontraron documentos para reindexar"
        except Exception as e:
            logger.error(f"Error reindexing: {e}")
            return f"âŒ Error al reindexar: {str(e)}"

    def get_faq_markdown(self) -> str:
        """Genera el texto Markdown de las preguntas frecuentes."""
        faqs = self.rag_service.get_frequent_questions()
        if not faqs:
            return "_No hay preguntas frecuentes registradas aÃºn._"
        lines = "\n".join(f"- {q}" for q in faqs)
        return f"**Preguntas frecuentes:**\n{lines}"
    
    def create_interface(self) -> gr.Blocks:
        """Crea la interfaz de Gradio actualizada con intent feedback"""
        with gr.Blocks(
            title="Sistema RAG Avanzado - InvestigaciÃ³n de Tesis",
            theme=gr.themes.Soft(),
            css="""
            .system-info {
                background-color: #f8f9fa !important;
                border: 1px solid #e9ecef !important;
                border-radius: 8px !important;
                padding: 12px !important;
                margin-top: 8px !important;
                font-size: 0.9em !important;
                color: #2c3e50 !important;
            }
            .system-info h3 {
                color: #34495e !important;
                font-weight: bold !important;
                margin-bottom: 8px !important;
            }
            .system-info p {
                color: #2c3e50 !important;
                margin-bottom: 4px !important;
            }
            .system-info strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            .intent-indicator {
                display: inline-block !important;
                padding: 4px 8px !important;
                border-radius: 12px !important;
                font-size: 0.8em !important;
                font-weight: bold !important;
                margin-right: 8px !important;
            }
            .definition { 
                background-color: #e3f2fd !important; 
                color: #1565c0 !important; 
            }
            .comparison { 
                background-color: #f3e5f5 !important; 
                color: #7b1fa2 !important; 
            }
            .state_of_art { 
                background-color: #e8f5e8 !important; 
                color: #2e7d32 !important; 
            }
            .gap_analysis { 
                background-color: #fff3e0 !important; 
                color: #ef6c00 !important; 
            }
            /* Asegurar que el texto en el panel lateral sea visible */
            .gr-column .gr-markdown {
                color: #2c3e50 !important;
            }
            .gr-column .gr-markdown h3 {
                color: #34495e !important;
                font-weight: bold !important;
            }
            .gr-column .gr-markdown strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            """
        ) as interface:
            
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 2rem;">
                <h1>ğŸ¤– Sistema RAG Avanzado para InvestigaciÃ³n AcadÃ©mica</h1>
                <p>Especializado en IA para Historias de Usuario - Con DetecciÃ³n Inteligente de IntenciÃ³n</p>
                <p><small>El sistema detecta automÃ¡ticamente el tipo de consulta y optimiza la respuesta accordingly</small></p>
            </div>
            """)
            
            with gr.Tabs():
                # Tab principal - Chat AcadÃ©mico
                with gr.TabItem("ğŸ’¬ Chat AcadÃ©mico Inteligente"):
                    gr.Markdown("### Asistente de InvestigaciÃ³n con IA")
                    gr.Markdown("""
                    Haz preguntas acadÃ©micas y observa cÃ³mo el sistema:
                    - ğŸ¯ **Detecta automÃ¡ticamente** el tipo de consulta (definiciÃ³n, comparaciÃ³n, estado del arte, gaps)
                    - ğŸ” **Expande tu consulta** con sinÃ³nimos acadÃ©micos relevantes  
                    - ğŸ¤– **Selecciona el modelo apropiado** (GPT-4o para anÃ¡lisis complejos, GPT-4o-mini para consultas simples)  
                    - âœ¨ **Optimiza la respuesta** usando templates acadÃ©micos especializados
                    """)
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            # Ãrea principal de chat
                            chatbot = gr.Chatbot(
                                label="ConversaciÃ³n AcadÃ©mica",
                                height=500,
                                type='messages',
                                show_label=True
                            )
                            
                            with gr.Row():
                                msg = gr.Textbox(
                                    label="Tu pregunta de investigaciÃ³n",
                                    placeholder="Ej: Compare las metodologÃ­as de IA para historias de usuario...",
                                    scale=4,
                                    lines=2
                                )
                                send_btn = gr.Button("Enviar", variant="primary", scale=1)
                            
                            with gr.Row():
                                clear_btn = gr.Button("ğŸ—‘ï¸ Limpiar Chat", variant="secondary")
                        
                        with gr.Column(scale=1):
                            # Panel de informaciÃ³n del sistema
                            system_info_display = gr.Markdown(
                                label="ğŸ“Š InformaciÃ³n del Sistema",
                                value="*EnvÃ­a una consulta para ver cÃ³mo el sistema analiza tu pregunta*",
                                elem_classes=["system-info"],
                                visible=True
                            )
                    
                    # Ejemplos acadÃ©micos especÃ­ficos organizados por tipo de intenciÃ³n
                    with gr.Accordion("ğŸ“‹ Ejemplos por Tipo de Consulta", open=False):
                        gr.Markdown("""
                        **ğŸ”µ Definiciones Conceptuales:**
                        - "Â¿QuÃ© es Natural Language Processing en requirements engineering?"
                        - "Define machine learning aplicado a historias de usuario"
                        - "Explica el concepto de automated requirements generation"
                        
                        **ğŸŸ£ AnÃ¡lisis Comparativos:**
                        - "Compara supervised vs unsupervised learning para user stories"
                        - "Diferencias entre rule-based y ML approaches en requirements"
                        - "Ventajas y desventajas de BERT vs GPT para anÃ¡lisis de texto"
                        
                        **ğŸŸ¢ Estado del Arte:**
                        - "Estado del arte en IA para automatizaciÃ³n de requirements"
                        - "Enfoques actuales en NLP para historias de usuario"
                        - "Tendencias recientes en AI-assisted software development"
                        
                        **ğŸŸ  AnÃ¡lisis de Gaps:**
                        - "Â¿QuÃ© limitaciones tienen los mÃ©todos actuales de NLP para user stories?"
                        - "Gaps de investigaciÃ³n en automated requirements engineering"
                        - "Â¿QuÃ© oportunidades existen para mejorar las tÃ©cnicas actuales?"
                        """)

                    # FAQ dinÃ¡micas
                    faq_display = gr.Markdown(value=self.get_faq_markdown())
                    
                    def respond(message, chat_history):
                        if not message.strip():
                            return chat_history, "", self.get_faq_markdown(), ""
                        
                        # Obtener respuesta y informaciÃ³n del sistema
                        bot_response, system_info = self.chat_response(message, chat_history)
                        
                        # Agregar al historial en formato correcto para Gradio
                        chat_history.append({"role": "user", "content": message})
                        chat_history.append({"role": "assistant", "content": bot_response})

                        return chat_history, "", self.get_faq_markdown(), system_info
                    
                    # Event handlers para el chat
                    send_btn.click(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    msg.submit(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    clear_btn.click(
                        lambda: ([], "", self.get_faq_markdown(), "*EnvÃ­a una consulta para ver el anÃ¡lisis del sistema*"),
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                
                # Tab de administraciÃ³n
                with gr.TabItem("âš™ï¸ AdministraciÃ³n del Sistema"):
                    gr.Markdown("### GestiÃ³n del Sistema RAG Inteligente")
                    
                    with gr.Row():
                        init_btn = gr.Button("ğŸš€ Inicializar Sistema", variant="primary")
                        reindex_btn = gr.Button("ğŸ“š Reindexar Documentos", variant="secondary")
                    
                    status_output = gr.Textbox(
                        label="Estado del Sistema",
                        interactive=False,
                        lines=3
                    )
                    
                    # InformaciÃ³n del sistema
                    gr.Markdown("### ConfiguraciÃ³n del Sistema RAG Inteligente")
                    gr.Markdown(f"""
                    **ğŸ§  DetecciÃ³n de IntenciÃ³n AcadÃ©mica:**
                    - ğŸ¯ **Estado**: `{'Habilitada' if settings.enable_intent_detection else 'Deshabilitada'}`
                    - ğŸ“Š **Umbral de confianza**: `{settings.intent_confidence_threshold}`
                    - âš¡ **Tiempo mÃ¡ximo de procesamiento**: `{settings.intent_max_processing_time_ms}ms`
                    
                    **ğŸ” ExpansiÃ³n Inteligente de Consultas:**
                    - ğŸ¯ **Estado**: `{'Habilitada' if settings.enable_query_expansion else 'Deshabilitada'}`
                    - ğŸ“Š **MÃ¡ximo tÃ©rminos expandidos**: `{settings.max_expansion_terms}`
                    - ğŸ¨ **Estrategia de expansiÃ³n**: `{settings.expansion_strategy}`
                    - âš¡ **Tiempo mÃ¡ximo de procesamiento**: `{settings.expansion_max_processing_time_ms}ms`
                    
                    **ğŸ¤– SelecciÃ³n Inteligente de Modelos:**
                    - ğŸ§  **Modelo para consultas complejas**: `{settings.complex_model}`
                    - âš¡ **Modelo para consultas simples**: `{settings.simple_model}`
                    - ğŸ¯ **Umbral de complejidad**: `{settings.complexity_threshold}`
                    - ğŸ”„ **SelecciÃ³n automÃ¡tica**: `{'Activada' if settings.enable_smart_selection else 'Desactivada'}`
                    
                    **ğŸ“š ConfiguraciÃ³n RAG Base:**
                    - ğŸ“ **Directorio de documentos**: `{settings.documents_path}`
                    - ğŸ—ƒï¸ **Base de datos vectorial**: `{settings.vector_db_path}`
                    - ğŸ”¤ **Modelo de embeddings**: `{settings.embedding_model}`
                    - ğŸ“Š **TamaÃ±o de chunk**: `{settings.chunk_size}`
                    - ğŸ”— **Overlap de chunk**: `{settings.chunk_overlap}`
                    - ğŸ“– **Documentos por consulta**: `{settings.max_documents}`
                    """)
                
                # Tab de guÃ­a acadÃ©mica actualizada
                with gr.TabItem("ğŸ“š GuÃ­a de InvestigaciÃ³n Inteligente"):
                    gr.Markdown("""
                    ## ğŸ“ Sistema RAG Inteligente para InvestigaciÃ³n AcadÃ©mica
                    
                    ### ğŸ§  Inteligencia Artificial Integrada
                    
                    Este sistema combina **dos niveles de IA** para optimizar tu experiencia de investigaciÃ³n:
                    
                    #### ğŸ¯ **Nivel 1: DetecciÃ³n AutomÃ¡tica de IntenciÃ³n**
                    El sistema analiza tu consulta en **menos de 200ms** para determinar quÃ© tipo de respuesta necesitas:
                    
                    - **ğŸ“– DefiniciÃ³n Conceptual** â†’ Estructura la respuesta con definiciÃ³n formal, contexto histÃ³rico y aplicaciones
                    - **âš–ï¸ AnÃ¡lisis Comparativo** â†’ Organiza la informaciÃ³n en tablas comparativas y anÃ¡lisis sistemÃ¡tico  
                    - **ğŸŒŸ Estado del Arte** â†’ Presenta cronologÃ­a, tendencias actuales y consenso acadÃ©mico
                    - **ğŸ” AnÃ¡lisis de Gaps** â†’ Identifica limitaciones, oportunidades y direcciones futuras
                    
                    #### ğŸ¤– **Nivel 2: SelecciÃ³n Inteligente de Modelo**
                    Basado en la complejidad de tu consulta, elige automÃ¡ticamente:
                    
                    - **ğŸ§  GPT-4o** para anÃ¡lisis acadÃ©micos complejos, comparaciones metodolÃ³gicas y sÃ­ntesis profundas
                    - **âš¡ GPT-4o-mini** para definiciones claras, consultas directas y respuestas rÃ¡pidas
                    
                    ### ğŸš€ CÃ³mo Aprovechar al MÃ¡ximo el Sistema
                    
                    #### **Para InvestigaciÃ³n de Tesis sobre IA y User Stories:**
                    
                    **ğŸ” ExploraciÃ³n Inicial:**
                    1. "Estado del arte en IA para historias de usuario" (activarÃ¡ anÃ¡lisis cronolÃ³gico)
                    2. "Â¿QuÃ© es automated requirements generation?" (activarÃ¡ definiciÃ³n estructurada)
                    
                    **ğŸ“Š AnÃ¡lisis Comparativo:**
                    1. "Compara NLP vs Machine Learning para requirements analysis"
                    2. "Ventajas y desventajas de rule-based vs deep learning approaches"
                    
                    **ğŸ¯ IdentificaciÃ³n de Oportunidades:**
                    1. "Â¿QuÃ© limitaciones tienen las tÃ©cnicas actuales de NLP para user stories?"
                    2. "Gaps de investigaciÃ³n en automated requirements engineering"
                    
                    ### ğŸ’¡ Indicadores Visuales del Sistema
                    
                    Observa el **panel lateral** durante tus consultas para ver:
                    
                    - **ğŸ¯ Tipo de consulta detectada** con nivel de confianza
                    - **ğŸ¤– Modelo seleccionado** y razÃ³n de la selecciÃ³n  
                    - **âœ¨ OptimizaciÃ³n aplicada** (si usa template especializado)
                    - **ğŸ“š Fuentes consultadas** para tu respuesta especÃ­fica
                    
                    ### ğŸ“ Resultados de InvestigaciÃ³n Optimizados
                    
                    **Para Definiciones:**
                    - Estructura acadÃ©mica formal con contexto histÃ³rico
                    - Referencias a autores principales y papers fundamentales
                    - Conexiones con conceptos relacionados
                    
                    **Para Comparaciones:**
                    - Matrices comparativas sistemÃ¡ticas
                    - AnÃ¡lisis de ventajas/desventajas equilibrado
                    - Recomendaciones basadas en contexto de uso
                    
                    **Para Estado del Arte:**
                    - EvoluciÃ³n temporal de enfoques
                    - IdentificaciÃ³n de tendencias emergentes  
                    - AnÃ¡lisis de consenso vs controversias
                    
                    **Para AnÃ¡lisis de Gaps:**
                    - CategorizaciÃ³n de limitaciones por tipo
                    - Oportunidades especÃ­ficas de investigaciÃ³n
                    - ConexiÃ³n con trabajos futuros sugeridos
                    
                    ### ğŸ”¬ OptimizaciÃ³n para tu Dominio EspecÃ­fico
                    
                    El sistema estÃ¡ **pre-optimizado** para investigaciÃ³n en:
                    - âœ… Inteligencia Artificial aplicada a Software Engineering
                    - âœ… Natural Language Processing para Requirements  
                    - âœ… Machine Learning en User Story Analysis
                    - âœ… Automated Software Development Tools
                    - âœ… AI-Assisted Development Methodologies
                    
                    ### ğŸ“ˆ Consejos para Consultas de Alta Calidad
                    
                    **ğŸ¯ SÃ© especÃ­fico en tu intenciÃ³n:**
                    - âŒ "machine learning" 
                    - âœ… "Â¿QuÃ© tÃ©cnicas de machine learning se usan para analizar historias de usuario?"
                    
                    **ğŸ”— Conecta conceptos:**
                    - âŒ "NLP tools"
                    - âœ… "Compare herramientas de NLP para extracciÃ³n automÃ¡tica de requirements"
                    
                    **ğŸ“Š Solicita anÃ¡lisis estructurado:**
                    - âŒ "research gaps"
                    - âœ… "Â¿QuÃ© limitaciones identifican los estudios actuales en automated user story generation?"
                    
                    ### ğŸš€ El Futuro de tu InvestigaciÃ³n
                    
                    Con este sistema inteligente, puedes:
                    - **âš¡ Acelerar** tu revisiÃ³n de literatura 5-10x
                    - **ğŸ¯ Identificar** gaps de investigaciÃ³n automÃ¡ticamente  
                    - **ğŸ“Š Comparar** metodologÃ­as de manera sistemÃ¡tica
                    - **ğŸ” Descubrir** conexiones entre diferentes lÃ­neas de investigaciÃ³n
                    - **ğŸ“ˆ Optimizar** la calidad acadÃ©mica de tu anÃ¡lisis
                    """)
            
            # Event handlers
            init_btn.click(
                fn=self.initialize_service,
                outputs=status_output
            )
            
            reindex_btn.click(
                fn=self.reindex_documents,
                outputs=status_output
            )
        
        return interface
    
    def launch(self, **kwargs):
        """Lanza la aplicaciÃ³n"""
        interface = self.create_interface()
        
        # ConfiguraciÃ³n por defecto
        launch_kwargs = {
            'server_port': settings.server_port,
            'share': settings.share_gradio,
            'show_error': True,
            'quiet': False,
            **kwargs
        }
        
        logger.info(f"Launching RAG app with intelligent intent detection and model selection on port {launch_kwargs['server_port']}")
        interface.launch(**launch_kwargs)