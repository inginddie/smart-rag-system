# -*- coding: utf-8 -*-
import gradio as gr
from typing import List, Tuple
from src.services.rag_service import RAGService
from src.utils.logger import setup_logger
from config.settings import settings

logger = setup_logger()

class GradioRAGApp:
    """AplicaciÃ³n Gradio para el sistema RAG con selecciÃ³n inteligente de modelos"""
    
    def __init__(self):
        self.rag_service = RAGService()
        self.initialized = False
    
    def initialize_service(self) -> str:
        """Inicializa el servicio RAG"""
        try:
            if self.rag_service.initialize():
                self.initialized = True
                return "âœ… Sistema RAG inicializado correctamente con selecciÃ³n inteligente de modelos"
            else:
                return "âš ï¸ Sistema inicializado pero no se encontraron documentos para indexar"
        except Exception as e:
            logger.error(f"Error initializing service: {e}")
            return f"âŒ Error al inicializar: {str(e)}"
    
    def chat_response(self, message: str, history: List[Tuple[str, str]], show_technical_info: bool = False) -> str:
        """Maneja las respuestas del chat con control de informaciÃ³n tÃ©cnica"""
        if not self.initialized:
            return "âŒ El sistema no estÃ¡ inicializado. Por favor inicialÃ­zalo primero."
        
        if not message.strip():
            return "Por favor, escribe una pregunta."
        
        try:
            # Obtener respuesta con informaciÃ³n del modelo
            result = self.rag_service.query(message)
            response = result['answer']
            
            # Solo mostrar informaciÃ³n tÃ©cnica si se solicita explÃ­citamente o en modo DEBUG
            model_info = result.get('model_info', {})
            should_show_technical = (
                show_technical_info or 
                (settings.log_level == "DEBUG" and hasattr(settings, 'show_model_info_in_ui') and settings.show_model_info_in_ui)
            )
            
            if model_info and should_show_technical:
                model_name = model_info.get('selected_model', 'unknown')
                complexity = model_info.get('complexity_score', 0)
                response += f"\n\nğŸ“‹ *InformaciÃ³n tÃ©cnica: Procesado con {model_name} (complejidad: {complexity:.2f})*"
            
            return response
            
        except Exception as e:
            logger.error(f"Error in chat response: {e}")
            # Solo mostrar detalles tÃ©cnicos si estÃ¡ habilitado
            if settings.show_technical_errors:
            return f"âŒ Error al procesar la pregunta: {str(e)}"
            else:
                return "âŒ Error al procesar la pregunta. Por favor, intÃ©ntalo de nuevo o contacta al administrador."
    
    def reindex_documents(self) -> str:
        """Reindexar documentos"""
        try:
            count = self.rag_service.reindex_documents()
            if count > 0:
                return f"âœ… Reindexados {count} documentos correctamente"
            else:
                return "âš ï¸ No se encontraron documentos para reindexar"
        except Exception as e:
            logger.error(f"Error reindexing: {e}")
            return f"âŒ Error al reindexar: {str(e)}"

    def get_faq_markdown(self) -> str:
        """Genera el texto Markdown de las preguntas frecuentes."""
        faqs = self.rag_service.get_frequent_questions()
        if not faqs:
            return "_No hay preguntas frecuentes registradas aÃºn._"
        lines = "\n".join(f"- {q}" for q in faqs)
        return f"**Preguntas frecuentes:**\n{lines}"
    
    def create_interface(self) -> gr.Blocks:
        """Crea la interfaz de Gradio actualizada"""
        with gr.Blocks(
            title="Sistema RAG Avanzado - InvestigaciÃ³n de Tesis",
            theme=gr.themes.Soft(),
        ) as interface:
            
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 2rem;">
                <h1>ğŸ¤– Sistema RAG Avanzado para InvestigaciÃ³n</h1>
                <p>Especializado en IA para Historias de Usuario - SelecciÃ³n Inteligente de Modelos</p>
                <p><small>Usa automÃ¡ticamente GPT-4o para anÃ¡lisis complejos y GPT-4o-mini para consultas simples</small></p>
            </div>
            """)
            
            with gr.Tabs():
                # Tab principal - Chat
                with gr.TabItem("ğŸ’¬ Chat AcadÃ©mico"):
                    gr.Markdown("### Asistente de InvestigaciÃ³n")
                    gr.Markdown("Haz preguntas acadÃ©micas sobre tus documentos. El sistema seleccionarÃ¡ automÃ¡ticamente el modelo mÃ¡s apropiado.")
                    
                    # ChatInterface actualizado para nueva versiÃ³n de Gradio
                    chatbot = gr.Chatbot(
                        label="ConversaciÃ³n AcadÃ©mica",
                        height=400,
                        type='messages'  # Corregir warning de Gradio
                    )
                    
                    with gr.Row():
                        msg = gr.Textbox(
                            label="Tu pregunta de investigaciÃ³n",
                            placeholder="Ej: Compara las metodologÃ­as de IA para historias de usuario...",
                            scale=4
                        )
                        send_btn = gr.Button("Enviar", variant="primary", scale=1)
                    
                    with gr.Row():
                        clear_btn = gr.Button("ğŸ—‘ï¸ Limpiar Chat", variant="secondary")
                    
                    # Ejemplos acadÃ©micos especÃ­ficos para tu investigaciÃ³n
                    gr.Examples(
                        examples=[
                            "Â¿CuÃ¡les son las principales metodologÃ­as de IA para mejorar historias de usuario?",
                            "Compara los enfoques de NLP vs Machine Learning en requirements engineering",
                            "Â¿QuÃ© gaps de investigaciÃ³n existen en la automatizaciÃ³n de historias de usuario?",
                            "Analiza las mÃ©tricas de evaluaciÃ³n utilizadas en la literatura",
                            "Â¿QuÃ© tÃ©cnicas de deep learning se han aplicado a requirements?",
                            "Resume el estado del arte en IA para desarrollo Ã¡gil",
                        ],
                        inputs=msg
                    )

                    faq_display = gr.Markdown(value=self.get_faq_markdown())
                    
                    def respond(message, chat_history):
                        if not message.strip():
                            return chat_history, "", self.get_faq_markdown()
                        
                        # Obtener respuesta del RAG
                        bot_response = self.chat_response(message, chat_history)
                        
                        # Agregar al historial en formato correcto para Gradio
                        chat_history.append({"role": "user", "content": message})
                        chat_history.append({"role": "assistant", "content": bot_response})

                        return chat_history, "", self.get_faq_markdown()
                    
                    # Event handlers para el chat
                    send_btn.click(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display]
                    )
                    
                    msg.submit(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display]
                    )
                    
                    clear_btn.click(
                        lambda: ([], "", self.get_faq_markdown()),
                        outputs=[chatbot, msg, faq_display]
                    )
                
                # Tab de administraciÃ³n
                with gr.TabItem("âš™ï¸ AdministraciÃ³n"):
                    gr.Markdown("### GestiÃ³n del Sistema RAG")
                    
                    with gr.Row():
                        init_btn = gr.Button("ğŸš€ Inicializar Sistema", variant="primary")
                        reindex_btn = gr.Button("ğŸ“š Reindexar Documentos", variant="secondary")
                    
                    status_output = gr.Textbox(
                        label="Estado del Sistema",
                        interactive=False,
                        lines=3
                    )
                    
                    # InformaciÃ³n del sistema
                    gr.Markdown("### ConfiguraciÃ³n Actual")
                    gr.Markdown(f"""
                    **SelecciÃ³n Inteligente de Modelos:**
                    - ğŸ§  **Modelo para consultas complejas**: `{settings.complex_model}`
                    - âš¡ **Modelo para consultas simples**: `{settings.simple_model}`
                    - ğŸ¯ **Umbral de complejidad**: `{settings.complexity_threshold}`
                    - ğŸ”„ **SelecciÃ³n automÃ¡tica**: `{'Activada' if settings.enable_smart_selection else 'Desactivada'}`
                    
                    **ConfiguraciÃ³n RAG:**
                    - ğŸ“ **Directorio de documentos**: `{settings.documents_path}`
                    - ğŸ—ƒï¸ **Base de datos vectorial**: `{settings.vector_db_path}`
                    - ğŸ”¤ **Modelo de embeddings**: `{settings.embedding_model}`
                    - ğŸ“Š **TamaÃ±o de chunk**: `{settings.chunk_size}`
                    - ğŸ”— **Overlap de chunk**: `{settings.chunk_overlap}`
                    - ğŸ“– **Documentos por consulta**: `{settings.max_documents}`
                    """)
                
                # Tab de ayuda acadÃ©mica
                with gr.TabItem("ğŸ“š GuÃ­a de InvestigaciÃ³n"):
                    gr.Markdown("""
                    ## ğŸ“ Sistema RAG para InvestigaciÃ³n de Tesis
                    
                    ### ğŸ§  SelecciÃ³n Inteligente de Modelos
                    
                    El sistema **selecciona automÃ¡ticamente** el modelo mÃ¡s apropiado:
                    
                    **GPT-4o (AnÃ¡lisis Complejo)** se activa con:
                    - ğŸ”¬ **Palabras acadÃ©micas**: "analiza", "compara", "evalÃºa", "metodologÃ­a"
                    - ğŸ“Š **AnÃ¡lisis crÃ­tico**: "ventajas y desventajas", "limitaciones", "gaps"
                    - ğŸ¯ **Estado del arte**: "literatura", "sÃ­ntesis", "framework"
                    - ğŸ“ **InvestigaciÃ³n**: "paper", "estudio", "hallazgos"
                    
                    **GPT-4o-mini (Consultas Simples)** para:
                    - â“ **Definiciones**: "Â¿QuÃ© es...?", "Define..."
                    - ğŸ“‹ **Listas**: "Lista las tÃ©cnicas...", "Enumera..."
                    - ğŸ” **BÃºsquedas bÃ¡sicas**: "Encuentra...", "Busca..."
                    
                    ### ğŸš€ Tipos de Consultas para tu Tesis
                    
                    #### **Estado del Arte** (â†’ GPT-4o)
                    - "Analiza el estado del arte en IA para historias de usuario"
                    - "Â¿CuÃ¡les son las metodologÃ­as principales en la literatura?"
                    - "Sintetiza los enfoques de NLP en requirements engineering"
                    
                    #### **Comparaciones MetodolÃ³gicas** (â†’ GPT-4o)
                    - "Compara los frameworks de Chen et al. vs Smith et al."
                    - "Â¿CuÃ¡les son las ventajas y desventajas de cada enfoque?"
                    - "EvalÃºa crÃ­ticamente las tÃ©cnicas de machine learning aplicadas"
                    
                    #### **Gaps de InvestigaciÃ³n** (â†’ GPT-4o)
                    - "Â¿QuÃ© limitaciones identifican los estudios actuales?"
                    - "Â¿DÃ³nde estÃ¡n los gaps en la automatizaciÃ³n de requirements?"
                    - "Â¿QuÃ© direcciones futuras sugiere la literatura?"
                    
                    #### **Consultas EspecÃ­ficas** (â†’ GPT-4o-mini)
                    - "Â¿QuÃ© es una historia de usuario?"
                    - "Lista las tÃ©cnicas de NLP mencionadas"
                    - "Define requirements engineering"
                    
                    ### ğŸ’¡ Consejos para Mejores Resultados
                    
                    1. **SÃ© especÃ­fico** en tus preguntas acadÃ©micas
                    2. **Usa terminologÃ­a tÃ©cnica** para activar anÃ¡lisis profundo
                    3. **Pregunta por comparaciones** para obtener sÃ­ntesis complejas
                    4. **Solicita gaps** para identificar oportunidades de investigaciÃ³n
                    5. **Pide citas especÃ­ficas** mencionando autores cuando sea posible
                    
                    ### ğŸ“– PreparaciÃ³n de Documentos
                    
                    1. **Organiza tus 159 PDFs** por categorÃ­as temÃ¡ticas
                    2. **Procesa por lotes** (20-30 papers a la vez)
                    3. **Verifica nombres** descriptivos de archivos
                    4. **Inicia con papers fundamentales** antes de casos especÃ­ficos
                    """)
            
            # Event handlers
            init_btn.click(
                fn=self.initialize_service,
                outputs=status_output
            )
            
            reindex_btn.click(
                fn=self.reindex_documents,
                outputs=status_output
            )
        
        return interface
    
    def launch(self, **kwargs):
        """Lanza la aplicaciÃ³n"""
        interface = self.create_interface()
        
        # ConfiguraciÃ³n por defecto
        launch_kwargs = {
            'server_port': settings.server_port,
            'share': settings.share_gradio,
            'show_error': True,
            'quiet': False,
            **kwargs
        }
        
        logger.info(f"Launching RAG app with smart model selection on port {launch_kwargs['server_port']}")
        interface.launch(**launch_kwargs)