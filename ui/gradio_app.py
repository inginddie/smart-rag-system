# -*- coding: utf-8 -*-
import gradio as gr
from typing import List, Tuple
from src.services.rag_service import RAGService
from src.utils.logger import setup_logger
from config.settings import settings

logger = setup_logger()

class GradioRAGApp:
    """Aplicaci√≥n Gradio para el sistema RAG con selecci√≥n inteligente de modelos y detecci√≥n de intenci√≥n acad√©mica"""
    
    def __init__(self):
        self.rag_service = RAGService()
        self.initialized = False
    
    def initialize_service(self) -> str:
        """Inicializa el servicio RAG"""
        try:
            if self.rag_service.initialize():
                self.initialized = True
                return "‚úÖ Sistema RAG inicializado correctamente con detecci√≥n de intenci√≥n acad√©mica habilitada"
            else:
                return "‚ö†Ô∏è Sistema inicializado pero no se encontraron documentos para indexar"
        except Exception as e:
            logger.error(f"Error initializing service: {e}")
            return f"‚ùå Error al inicializar: {str(e)}"
    
    def _format_intent_info(self, intent_info: dict) -> str:
        """Formatea la informaci√≥n de intenci√≥n para mostrar al usuario"""
        if not intent_info:
            return ""
        
        intent_type = intent_info.get('detected_intent', 'unknown')
        confidence = intent_info.get('confidence', 0)
        specialized_prompt = intent_info.get('specialized_prompt_used', False)
        processing_time = intent_info.get('processing_time_ms', 0)
        
        # Mapear tipos de intenci√≥n a nombres amigables
        intent_names = {
            'definition': 'üìñ Definici√≥n Conceptual',
            'comparison': '‚öñÔ∏è An√°lisis Comparativo', 
            'state_of_art': 'üåü Estado del Arte',
            'gap_analysis': 'üîç An√°lisis de Gaps',
            'unknown': '‚ùì Consulta General',
            'error': '‚ö†Ô∏è Error de Clasificaci√≥n'
        }
        
        intent_name = intent_names.get(intent_type, f'‚ùì {intent_type}')
        
        # Crear mensaje informativo
        info_parts = [f"**Tipo de consulta detectada:** {intent_name}"]
        
        if confidence > 0:
            confidence_emoji = "üéØ" if confidence >= 0.8 else "üé≤" if confidence >= 0.6 else "‚ùì"
            info_parts.append(f"**Confianza:** {confidence_emoji} {confidence:.0%}")
        
        if specialized_prompt and intent_type not in ['unknown', 'error']:
            info_parts.append("**Respuesta optimizada:** ‚ú® Usando template acad√©mico especializado")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de an√°lisis:** ‚ö° {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
    
    def _format_expansion_info(self, expansion_info: dict) -> str:
        """Formatea la informaci√≥n de expansi√≥n de consulta para mostrar al usuario"""
        if not expansion_info or expansion_info.get('expansion_count', 0) == 0:
            return ""
        
        expanded_terms = expansion_info.get('expanded_terms', [])
        processing_time = expansion_info.get('processing_time_ms', 0)
        
        info_parts = [f"**T√©rminos expandidos:** üîç {', '.join(expanded_terms[:5])}"]
        
        if len(expanded_terms) > 5:
            info_parts.append(f"*... y {len(expanded_terms) - 5} t√©rminos m√°s*")
        
        if processing_time > 0:
            info_parts.append(f"**Tiempo de expansi√≥n:** ‚ö° {processing_time:.1f}ms")
        
        return "\n".join(info_parts)
        """Formatea la informaci√≥n del modelo para mostrar al usuario"""
        if not model_info:
            return ""
        
        model_name = model_info.get('selected_model', 'unknown')
        complexity_score = model_info.get('complexity_score', 0)
        
        # Mapear modelos a nombres amigables
        model_names = {
            'gpt-4o': 'üß† GPT-4o (An√°lisis Complejo)',
            'gpt-4o-mini': '‚ö° GPT-4o-mini (Respuesta R√°pida)',
            'gpt-3.5-turbo': 'üí® GPT-3.5-turbo (Eficiente)'
        }
        
        model_display = model_names.get(model_name, f'ü§ñ {model_name}')
        
        info_parts = [f"**Modelo seleccionado:** {model_display}"]
        
        if complexity_score > 0:
            complexity_emoji = "üî•" if complexity_score >= 0.7 else "‚ö°" if complexity_score >= 0.4 else "üí®"
            info_parts.append(f"**Complejidad detectada:** {complexity_emoji} {complexity_score:.0%}")
        
        return "\n".join(info_parts)
    
    def chat_response(self, message: str, history: List[Tuple[str, str]]) -> Tuple[str, str]:
        """
        Maneja las respuestas del chat con informaci√≥n enriquecida de intenci√≥n y modelo
        
        Returns:
            Tuple[respuesta_principal, informaci√≥n_del_sistema]
        """
        if not self.initialized:
            return "‚ùå El sistema no est√° inicializado. Por favor inicial√≠zalo primero.", ""
        
        if not message.strip():
            return "Por favor, escribe una pregunta.", ""
        
        try:
            # Obtener respuesta completa con metadata
            result = self.rag_service.query(message, include_sources=True)
            
            # Respuesta principal
            main_response = result['answer']
            
            # Informaci√≥n del sistema (intent + model + expansion)
            system_info_parts = []
            
            # Agregar informaci√≥n de intenci√≥n si est√° disponible
            intent_info = result.get('intent_info', {})
            if intent_info:
                intent_details = self._format_intent_info(intent_info)
                if intent_details:
                    system_info_parts.append("### üéØ An√°lisis de Consulta")
                    system_info_parts.append(intent_details)
            
            # Agregar informaci√≥n de expansi√≥n si est√° disponible
            expansion_info = result.get('expansion_info', {})
            if expansion_info:
                expansion_details = self._format_expansion_info(expansion_info)
                if expansion_details:
                    system_info_parts.append("### üîç Expansi√≥n de Consulta")
                    system_info_parts.append(expansion_details)
            
            # Agregar informaci√≥n del modelo si est√° disponible
            model_info = result.get('model_info', {})
            if model_info:
                model_details = self._format_model_info(model_info)
                if model_details:
                    system_info_parts.append("### ü§ñ Selecci√≥n de Modelo")
                    system_info_parts.append(model_details)
            
            # Agregar informaci√≥n de fuentes si est√° disponible
            sources = result.get('sources', [])
            if sources:
                system_info_parts.append("### üìö Fuentes Consultadas")
                source_list = []
                for i, source in enumerate(sources[:3], 1):  # Mostrar m√°ximo 3 fuentes
                    file_name = source.get('metadata', {}).get('file_name', 'Documento desconocido')
                    source_list.append(f"{i}. **{file_name}**")
                system_info_parts.append("\n".join(source_list))
                
                if len(sources) > 3:
                    system_info_parts.append(f"*... y {len(sources) - 3} fuentes adicionales*")
            
            # Combinar informaci√≥n del sistema
            system_info = "\n\n".join(system_info_parts) if system_info_parts else ""
            
            return main_response, system_info
            
        except Exception as e:
            logger.error(f"Error in chat response: {e}")
            error_msg = f"‚ùå Error al procesar la pregunta: {str(e)}"
            return error_msg, ""
    
    def reindex_documents(self) -> str:
        """Reindexar documentos"""
        try:
            count = self.rag_service.reindex_documents()
            if count > 0:
                return f"‚úÖ Reindexados {count} documentos correctamente"
            else:
                return "‚ö†Ô∏è No se encontraron documentos para reindexar"
        except Exception as e:
            logger.error(f"Error reindexing: {e}")
            return f"‚ùå Error al reindexar: {str(e)}"

    def get_faq_markdown(self) -> str:
        """Genera el texto Markdown de las preguntas frecuentes."""
        faqs = self.rag_service.get_frequent_questions()
        if not faqs:
            return "_No hay preguntas frecuentes registradas a√∫n._"
        lines = "\n".join(f"- {q}" for q in faqs)
        return f"**Preguntas frecuentes:**\n{lines}"
    
    def create_interface(self) -> gr.Blocks:
        """Crea la interfaz de Gradio actualizada con intent feedback"""
        with gr.Blocks(
            title="Sistema RAG Avanzado - Investigaci√≥n de Tesis",
            theme=gr.themes.Soft(),
            css="""
            .system-info {
                background-color: #f8f9fa !important;
                border: 1px solid #e9ecef !important;
                border-radius: 8px !important;
                padding: 12px !important;
                margin-top: 8px !important;
                font-size: 0.9em !important;
                color: #2c3e50 !important;
            }
            .system-info h3 {
                color: #34495e !important;
                font-weight: bold !important;
                margin-bottom: 8px !important;
            }
            .system-info p {
                color: #2c3e50 !important;
                margin-bottom: 4px !important;
            }
            .system-info strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            .intent-indicator {
                display: inline-block !important;
                padding: 4px 8px !important;
                border-radius: 12px !important;
                font-size: 0.8em !important;
                font-weight: bold !important;
                margin-right: 8px !important;
            }
            .definition { 
                background-color: #e3f2fd !important; 
                color: #1565c0 !important; 
            }
            .comparison { 
                background-color: #f3e5f5 !important; 
                color: #7b1fa2 !important; 
            }
            .state_of_art { 
                background-color: #e8f5e8 !important; 
                color: #2e7d32 !important; 
            }
            .gap_analysis { 
                background-color: #fff3e0 !important; 
                color: #ef6c00 !important; 
            }
            /* Asegurar que el texto en el panel lateral sea visible */
            .gr-column .gr-markdown {
                color: #2c3e50 !important;
            }
            .gr-column .gr-markdown h3 {
                color: #34495e !important;
                font-weight: bold !important;
            }
            .gr-column .gr-markdown strong {
                color: #2c3e50 !important;
                font-weight: bold !important;
            }
            """
        ) as interface:
            
            gr.HTML("""
            <div style="text-align: center; margin-bottom: 2rem;">
                <h1>ü§ñ Sistema RAG Avanzado para Investigaci√≥n Acad√©mica</h1>
                <p>Especializado en IA para Historias de Usuario - Con Detecci√≥n Inteligente de Intenci√≥n</p>
                <p><small>El sistema detecta autom√°ticamente el tipo de consulta y optimiza la respuesta accordingly</small></p>
            </div>
            """)
            
            with gr.Tabs():
                # Tab principal - Chat Acad√©mico
                with gr.TabItem("üí¨ Chat Acad√©mico Inteligente"):
                    gr.Markdown("### Asistente de Investigaci√≥n con IA")
                    gr.Markdown("""
                    Haz preguntas acad√©micas y observa c√≥mo el sistema:
                    - üéØ **Detecta autom√°ticamente** el tipo de consulta (definici√≥n, comparaci√≥n, estado del arte, gaps)
                    - üîç **Expande tu consulta** con sin√≥nimos acad√©micos relevantes  
                    - ü§ñ **Selecciona el modelo apropiado** (GPT-4o para an√°lisis complejos, GPT-4o-mini para consultas simples)  
                    - ‚ú® **Optimiza la respuesta** usando templates acad√©micos especializados
                    """)
                    
                    with gr.Row():
                        with gr.Column(scale=2):
                            # √Årea principal de chat
                            chatbot = gr.Chatbot(
                                label="Conversaci√≥n Acad√©mica",
                                height=500,
                                type='messages',
                                show_label=True
                            )
                            
                            with gr.Row():
                                msg = gr.Textbox(
                                    label="Tu pregunta de investigaci√≥n",
                                    placeholder="Ej: Compare las metodolog√≠as de IA para historias de usuario...",
                                    scale=4,
                                    lines=2
                                )
                                send_btn = gr.Button("Enviar", variant="primary", scale=1)
                            
                            with gr.Row():
                                clear_btn = gr.Button("üóëÔ∏è Limpiar Chat", variant="secondary")
                        
                        with gr.Column(scale=1):
                            # Panel de informaci√≥n del sistema
                            system_info_display = gr.Markdown(
                                label="üìä Informaci√≥n del Sistema",
                                value="*Env√≠a una consulta para ver c√≥mo el sistema analiza tu pregunta*",
                                elem_classes=["system-info"],
                                visible=True
                            )
                    
                    # Ejemplos acad√©micos espec√≠ficos organizados por tipo de intenci√≥n
                    with gr.Accordion("üìã Ejemplos por Tipo de Consulta", open=False):
                        gr.Markdown("""
                        **üîµ Definiciones Conceptuales:**
                        - "¬øQu√© es Natural Language Processing en requirements engineering?"
                        - "Define machine learning aplicado a historias de usuario"
                        - "Explica el concepto de automated requirements generation"
                        
                        **üü£ An√°lisis Comparativos:**
                        - "Compara supervised vs unsupervised learning para user stories"
                        - "Diferencias entre rule-based y ML approaches en requirements"
                        - "Ventajas y desventajas de BERT vs GPT para an√°lisis de texto"
                        
                        **üü¢ Estado del Arte:**
                        - "Estado del arte en IA para automatizaci√≥n de requirements"
                        - "Enfoques actuales en NLP para historias de usuario"
                        - "Tendencias recientes en AI-assisted software development"
                        
                        **üü† An√°lisis de Gaps:**
                        - "¬øQu√© limitaciones tienen los m√©todos actuales de NLP para user stories?"
                        - "Gaps de investigaci√≥n en automated requirements engineering"
                        - "¬øQu√© oportunidades existen para mejorar las t√©cnicas actuales?"
                        """)

                    # FAQ din√°micas
                    faq_display = gr.Markdown(value=self.get_faq_markdown())
                    
                    def respond(message, chat_history):
                        if not message.strip():
                            return chat_history, "", self.get_faq_markdown(), ""
                        
                        # Obtener respuesta y informaci√≥n del sistema
                        bot_response, system_info = self.chat_response(message, chat_history)
                        
                        # Agregar al historial en formato correcto para Gradio
                        chat_history.append({"role": "user", "content": message})
                        chat_history.append({"role": "assistant", "content": bot_response})

                        return chat_history, "", self.get_faq_markdown(), system_info
                    
                    # Event handlers para el chat
                    send_btn.click(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    msg.submit(
                        respond,
                        inputs=[msg, chatbot],
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                    
                    clear_btn.click(
                        lambda: ([], "", self.get_faq_markdown(), "*Env√≠a una consulta para ver el an√°lisis del sistema*"),
                        outputs=[chatbot, msg, faq_display, system_info_display]
                    )
                
                # Tab de administraci√≥n
                with gr.TabItem("‚öôÔ∏è Administraci√≥n del Sistema"):
                    gr.Markdown("### Gesti√≥n del Sistema RAG Inteligente")
                    
                    with gr.Row():
                        init_btn = gr.Button("üöÄ Inicializar Sistema", variant="primary")
                        reindex_btn = gr.Button("üìö Reindexar Documentos", variant="secondary")
                    
                    status_output = gr.Textbox(
                        label="Estado del Sistema",
                        interactive=False,
                        lines=3
                    )
                    
                    # Informaci√≥n del sistema
                    gr.Markdown("### Configuraci√≥n del Sistema RAG Inteligente")
                    gr.Markdown(f"""
                    **üß† Detecci√≥n de Intenci√≥n Acad√©mica:**
                    - üéØ **Estado**: `{'Habilitada' if settings.enable_intent_detection else 'Deshabilitada'}`
                    - üìä **Umbral de confianza**: `{settings.intent_confidence_threshold}`
                    - ‚ö° **Tiempo m√°ximo de procesamiento**: `{settings.intent_max_processing_time_ms}ms`
                    
                    **üîç Expansi√≥n Inteligente de Consultas:**
                    - üéØ **Estado**: `{'Habilitada' if settings.enable_query_expansion else 'Deshabilitada'}`
                    - üìä **M√°ximo t√©rminos expandidos**: `{settings.max_expansion_terms}`
                    - üé® **Estrategia de expansi√≥n**: `{settings.expansion_strategy}`
                    - ‚ö° **Tiempo m√°ximo de procesamiento**: `{settings.expansion_max_processing_time_ms}ms`
                    
                    **ü§ñ Selecci√≥n Inteligente de Modelos:**
                    - üß† **Modelo para consultas complejas**: `{settings.complex_model}`
                    - ‚ö° **Modelo para consultas simples**: `{settings.simple_model}`
                    - üéØ **Umbral de complejidad**: `{settings.complexity_threshold}`
                    - üîÑ **Selecci√≥n autom√°tica**: `{'Activada' if settings.enable_smart_selection else 'Desactivada'}`
                    
                    **üìö Configuraci√≥n RAG Base:**
                    - üìÅ **Directorio de documentos**: `{settings.documents_path}`
                    - üóÉÔ∏è **Base de datos vectorial**: `{settings.vector_db_path}`
                    - üî§ **Modelo de embeddings**: `{settings.embedding_model}`
                    - üìä **Tama√±o de chunk**: `{settings.chunk_size}`
                    - üîó **Overlap de chunk**: `{settings.chunk_overlap}`
                    - üìñ **Documentos por consulta**: `{settings.max_documents}`
                    """)
                
                # Tab de gu√≠a acad√©mica actualizada
                with gr.TabItem("üìö Gu√≠a de Investigaci√≥n Inteligente"):
                    gr.Markdown("""
                    ## üéì Sistema RAG Inteligente para Investigaci√≥n Acad√©mica
                    
                    ### üß† Inteligencia Artificial Integrada
                    
                    Este sistema combina **dos niveles de IA** para optimizar tu experiencia de investigaci√≥n:
                    
                    #### üéØ **Nivel 1: Detecci√≥n Autom√°tica de Intenci√≥n**
                    El sistema analiza tu consulta en **menos de 200ms** para determinar qu√© tipo de respuesta necesitas:
                    
                    - **üìñ Definici√≥n Conceptual** ‚Üí Estructura la respuesta con definici√≥n formal, contexto hist√≥rico y aplicaciones
                    - **‚öñÔ∏è An√°lisis Comparativo** ‚Üí Organiza la informaci√≥n en tablas comparativas y an√°lisis sistem√°tico  
                    - **üåü Estado del Arte** ‚Üí Presenta cronolog√≠a, tendencias actuales y consenso acad√©mico
                    - **üîç An√°lisis de Gaps** ‚Üí Identifica limitaciones, oportunidades y direcciones futuras
                    
                    #### ü§ñ **Nivel 2: Selecci√≥n Inteligente de Modelo**
                    Basado en la complejidad de tu consulta, elige autom√°ticamente:
                    
                    - **üß† GPT-4o** para an√°lisis acad√©micos complejos, comparaciones metodol√≥gicas y s√≠ntesis profundas
                    - **‚ö° GPT-4o-mini** para definiciones claras, consultas directas y respuestas r√°pidas
                    
                    ### üöÄ C√≥mo Aprovechar al M√°ximo el Sistema
                    
                    #### **Para Investigaci√≥n de Tesis sobre IA y User Stories:**
                    
                    **üîç Exploraci√≥n Inicial:**
                    1. "Estado del arte en IA para historias de usuario" (activar√° an√°lisis cronol√≥gico)
                    2. "¬øQu√© es automated requirements generation?" (activar√° definici√≥n estructurada)
                    
                    **üìä An√°lisis Comparativo:**
                    1. "Compara NLP vs Machine Learning para requirements analysis"
                    2. "Ventajas y desventajas de rule-based vs deep learning approaches"
                    
                    **üéØ Identificaci√≥n de Oportunidades:**
                    1. "¬øQu√© limitaciones tienen las t√©cnicas actuales de NLP para user stories?"
                    2. "Gaps de investigaci√≥n en automated requirements engineering"
                    
                    ### üí° Indicadores Visuales del Sistema
                    
                    Observa el **panel lateral** durante tus consultas para ver:
                    
                    - **üéØ Tipo de consulta detectada** con nivel de confianza
                    - **ü§ñ Modelo seleccionado** y raz√≥n de la selecci√≥n  
                    - **‚ú® Optimizaci√≥n aplicada** (si usa template especializado)
                    - **üìö Fuentes consultadas** para tu respuesta espec√≠fica
                    
                    ### üéì Resultados de Investigaci√≥n Optimizados
                    
                    **Para Definiciones:**
                    - Estructura acad√©mica formal con contexto hist√≥rico
                    - Referencias a autores principales y papers fundamentales
                    - Conexiones con conceptos relacionados
                    
                    **Para Comparaciones:**
                    - Matrices comparativas sistem√°ticas
                    - An√°lisis de ventajas/desventajas equilibrado
                    - Recomendaciones basadas en contexto de uso
                    
                    **Para Estado del Arte:**
                    - Evoluci√≥n temporal de enfoques
                    - Identificaci√≥n de tendencias emergentes  
                    - An√°lisis de consenso vs controversias
                    
                    **Para An√°lisis de Gaps:**
                    - Categorizaci√≥n de limitaciones por tipo
                    - Oportunidades espec√≠ficas de investigaci√≥n
                    - Conexi√≥n con trabajos futuros sugeridos
                    
                    ### üî¨ Optimizaci√≥n para tu Dominio Espec√≠fico
                    
                    El sistema est√° **pre-optimizado** para investigaci√≥n en:
                    - ‚úÖ Inteligencia Artificial aplicada a Software Engineering
                    - ‚úÖ Natural Language Processing para Requirements  
                    - ‚úÖ Machine Learning en User Story Analysis
                    - ‚úÖ Automated Software Development Tools
                    - ‚úÖ AI-Assisted Development Methodologies
                    
                    ### üìà Consejos para Consultas de Alta Calidad
                    
                    **üéØ S√© espec√≠fico en tu intenci√≥n:**
                    - ‚ùå "machine learning" 
                    - ‚úÖ "¬øQu√© t√©cnicas de machine learning se usan para analizar historias de usuario?"
                    
                    **üîó Conecta conceptos:**
                    - ‚ùå "NLP tools"
                    - ‚úÖ "Compare herramientas de NLP para extracci√≥n autom√°tica de requirements"
                    
                    **üìä Solicita an√°lisis estructurado:**
                    - ‚ùå "research gaps"
                    - ‚úÖ "¬øQu√© limitaciones identifican los estudios actuales en automated user story generation?"
                    
                    ### üöÄ El Futuro de tu Investigaci√≥n
                    
                    Con este sistema inteligente, puedes:
                    - **‚ö° Acelerar** tu revisi√≥n de literatura 5-10x
                    - **üéØ Identificar** gaps de investigaci√≥n autom√°ticamente  
                    - **üìä Comparar** metodolog√≠as de manera sistem√°tica
                    - **üîç Descubrir** conexiones entre diferentes l√≠neas de investigaci√≥n
                    - **üìà Optimizar** la calidad acad√©mica de tu an√°lisis
                    """)
            
            # Event handlers
            init_btn.click(
                fn=self.initialize_service,
                outputs=status_output
            )
            
            reindex_btn.click(
                fn=self.reindex_documents,
                outputs=status_output
            )
        
        return interface
    
    def launch(self, **kwargs):
        """Lanza la aplicaci√≥n"""
        interface = self.create_interface()
        
        # Configuraci√≥n por defecto
        launch_kwargs = {
            'server_port': settings.server_port,
            'share': settings.share_gradio,
            'show_error': True,
            'quiet': False,
            **kwargs
        }
        
        logger.info(f"Launching RAG app with intelligent intent detection and model selection on port {launch_kwargs['server_port']}")
        interface.launch(**launch_kwargs)